{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score, recall_score, precision_score\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model,Sequential\n",
    "from tensorflow.keras.layers import Input, Dense, Activation,Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Height</th>\n",
       "      <th>Weight</th>\n",
       "      <th>family_history_with_overweight</th>\n",
       "      <th>FAVC</th>\n",
       "      <th>FCVC</th>\n",
       "      <th>NCP</th>\n",
       "      <th>CAEC</th>\n",
       "      <th>SMOKE</th>\n",
       "      <th>CH2O</th>\n",
       "      <th>SCC</th>\n",
       "      <th>FAF</th>\n",
       "      <th>TUE</th>\n",
       "      <th>CALC</th>\n",
       "      <th>MTRANS</th>\n",
       "      <th>NObeyesdad</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Female</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>1.620000</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>no</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>no</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>no</td>\n",
       "      <td>Public_Transportation</td>\n",
       "      <td>Normal_Weight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Female</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>1.520000</td>\n",
       "      <td>56.000000</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>yes</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>yes</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>Public_Transportation</td>\n",
       "      <td>Normal_Weight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Male</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>1.800000</td>\n",
       "      <td>77.000000</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>no</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>no</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>Frequently</td>\n",
       "      <td>Public_Transportation</td>\n",
       "      <td>Normal_Weight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Male</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>1.800000</td>\n",
       "      <td>87.000000</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>no</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>no</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Frequently</td>\n",
       "      <td>Walking</td>\n",
       "      <td>Overweight_Level_I</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Male</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>1.780000</td>\n",
       "      <td>89.800000</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>no</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>no</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>Public_Transportation</td>\n",
       "      <td>Overweight_Level_II</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2106</th>\n",
       "      <td>Female</td>\n",
       "      <td>20.976842</td>\n",
       "      <td>1.710730</td>\n",
       "      <td>131.408528</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>no</td>\n",
       "      <td>1.728139</td>\n",
       "      <td>no</td>\n",
       "      <td>1.676269</td>\n",
       "      <td>0.906247</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>Public_Transportation</td>\n",
       "      <td>Obesity_Type_III</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2107</th>\n",
       "      <td>Female</td>\n",
       "      <td>21.982942</td>\n",
       "      <td>1.748584</td>\n",
       "      <td>133.742943</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>no</td>\n",
       "      <td>2.005130</td>\n",
       "      <td>no</td>\n",
       "      <td>1.341390</td>\n",
       "      <td>0.599270</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>Public_Transportation</td>\n",
       "      <td>Obesity_Type_III</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2108</th>\n",
       "      <td>Female</td>\n",
       "      <td>22.524036</td>\n",
       "      <td>1.752206</td>\n",
       "      <td>133.689352</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>no</td>\n",
       "      <td>2.054193</td>\n",
       "      <td>no</td>\n",
       "      <td>1.414209</td>\n",
       "      <td>0.646288</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>Public_Transportation</td>\n",
       "      <td>Obesity_Type_III</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2109</th>\n",
       "      <td>Female</td>\n",
       "      <td>24.361936</td>\n",
       "      <td>1.739450</td>\n",
       "      <td>133.346641</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>no</td>\n",
       "      <td>2.852339</td>\n",
       "      <td>no</td>\n",
       "      <td>1.139107</td>\n",
       "      <td>0.586035</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>Public_Transportation</td>\n",
       "      <td>Obesity_Type_III</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2110</th>\n",
       "      <td>Female</td>\n",
       "      <td>23.664709</td>\n",
       "      <td>1.738836</td>\n",
       "      <td>133.472641</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>no</td>\n",
       "      <td>2.863513</td>\n",
       "      <td>no</td>\n",
       "      <td>1.026452</td>\n",
       "      <td>0.714137</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>Public_Transportation</td>\n",
       "      <td>Obesity_Type_III</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2111 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Gender        Age    Height      Weight family_history_with_overweight  \\\n",
       "0     Female  21.000000  1.620000   64.000000                            yes   \n",
       "1     Female  21.000000  1.520000   56.000000                            yes   \n",
       "2       Male  23.000000  1.800000   77.000000                            yes   \n",
       "3       Male  27.000000  1.800000   87.000000                             no   \n",
       "4       Male  22.000000  1.780000   89.800000                             no   \n",
       "...      ...        ...       ...         ...                            ...   \n",
       "2106  Female  20.976842  1.710730  131.408528                            yes   \n",
       "2107  Female  21.982942  1.748584  133.742943                            yes   \n",
       "2108  Female  22.524036  1.752206  133.689352                            yes   \n",
       "2109  Female  24.361936  1.739450  133.346641                            yes   \n",
       "2110  Female  23.664709  1.738836  133.472641                            yes   \n",
       "\n",
       "     FAVC  FCVC  NCP       CAEC SMOKE      CH2O  SCC       FAF       TUE  \\\n",
       "0      no   2.0  3.0  Sometimes    no  2.000000   no  0.000000  1.000000   \n",
       "1      no   3.0  3.0  Sometimes   yes  3.000000  yes  3.000000  0.000000   \n",
       "2      no   2.0  3.0  Sometimes    no  2.000000   no  2.000000  1.000000   \n",
       "3      no   3.0  3.0  Sometimes    no  2.000000   no  2.000000  0.000000   \n",
       "4      no   2.0  1.0  Sometimes    no  2.000000   no  0.000000  0.000000   \n",
       "...   ...   ...  ...        ...   ...       ...  ...       ...       ...   \n",
       "2106  yes   3.0  3.0  Sometimes    no  1.728139   no  1.676269  0.906247   \n",
       "2107  yes   3.0  3.0  Sometimes    no  2.005130   no  1.341390  0.599270   \n",
       "2108  yes   3.0  3.0  Sometimes    no  2.054193   no  1.414209  0.646288   \n",
       "2109  yes   3.0  3.0  Sometimes    no  2.852339   no  1.139107  0.586035   \n",
       "2110  yes   3.0  3.0  Sometimes    no  2.863513   no  1.026452  0.714137   \n",
       "\n",
       "            CALC                 MTRANS           NObeyesdad  \n",
       "0             no  Public_Transportation        Normal_Weight  \n",
       "1      Sometimes  Public_Transportation        Normal_Weight  \n",
       "2     Frequently  Public_Transportation        Normal_Weight  \n",
       "3     Frequently                Walking   Overweight_Level_I  \n",
       "4      Sometimes  Public_Transportation  Overweight_Level_II  \n",
       "...          ...                    ...                  ...  \n",
       "2106   Sometimes  Public_Transportation     Obesity_Type_III  \n",
       "2107   Sometimes  Public_Transportation     Obesity_Type_III  \n",
       "2108   Sometimes  Public_Transportation     Obesity_Type_III  \n",
       "2109   Sometimes  Public_Transportation     Obesity_Type_III  \n",
       "2110   Sometimes  Public_Transportation     Obesity_Type_III  \n",
       "\n",
       "[2111 rows x 17 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_data=pd.read_csv('ObesityDataSet_raw_and_data_sinthetic.csv')\n",
    "df_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_data['NObeyesdad'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_x\n",
    "df_data.loc()[df_data['family_history_with_overweight']=='no','family_history_with_overweight']=0\n",
    "df_data.loc()[df_data['family_history_with_overweight']=='yes','family_history_with_overweight']=1\n",
    "\n",
    "df_data.loc()[df_data['FAVC']=='no','FAVC']=0\n",
    "df_data.loc()[df_data['FAVC']=='yes','FAVC']=1\n",
    "\n",
    "df_data.loc()[df_data['SMOKE']=='no','SMOKE']=0\n",
    "df_data.loc()[df_data['SMOKE']=='yes','SMOKE']=1\n",
    "\n",
    "df_data.loc()[df_data['SCC']=='no','SCC']=0\n",
    "df_data.loc()[df_data['SCC']=='yes','SCC']=1\n",
    "\n",
    "df_data.loc()[df_data['CAEC']=='No','CAEC']=1\n",
    "df_data.loc()[df_data['CAEC']=='no','CAEC']=1\n",
    "df_data.loc()[df_data['CAEC']=='Sometimes','CAEC']=2\n",
    "df_data.loc()[df_data['CAEC']=='Frequently','CAEC']=3\n",
    "df_data.loc()[df_data['CAEC']=='Always','CAEC']=4\n",
    "\n",
    "df_data.loc()[df_data['CALC']=='no','CALC']=1\n",
    "df_data.loc()[df_data['CALC']=='Sometimes','CALC']=2\n",
    "df_data.loc()[df_data['CALC']=='Frequently','CALC']=3\n",
    "df_data.loc()[df_data['CALC']=='Always','CALC']=4\n",
    "\n",
    "df_data.loc()[df_data['Gender']=='Female','Gender']=0\n",
    "df_data.loc()[df_data['Gender']=='Male','Gender']=1\n",
    "df_data\n",
    "df_data.loc()[df_data['MTRANS']=='Public_Transportation','MTRANS']=0\n",
    "df_data.loc()[df_data['MTRANS']=='Walking','MTRANS']=1\n",
    "\n",
    "df_data.loc()[df_data['NObeyesdad']=='Normal_Weight','NObeyesdad']=0\n",
    "df_data.loc()[df_data['NObeyesdad']=='Obesity_Type_I','NObeyesdad']=1\n",
    "df_data.loc()[df_data['NObeyesdad']=='Obesity_Type_II','NObeyesdad']=2\n",
    "\n",
    "df_data.loc()[df_data['NObeyesdad']=='Obesity_Type_III','NObeyesdad']=3\n",
    "\n",
    "df_data.loc()[df_data['NObeyesdad']=='Overweight_Level_I','NObeyesdad']=4\n",
    "df_data.loc()[df_data['NObeyesdad']=='Overweight_Level_II','NObeyesdad']=5\n",
    "df_data.loc()[df_data['NObeyesdad']=='Insufficient_Weight','NObeyesdad']=6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data[['family_history_with_overweight', 'FAVC', 'CAEC', 'SMOKE', 'SCC','CALC']]=df_data[\n",
    "    ['family_history_with_overweight', 'FAVC', 'CAEC', 'SMOKE', 'SCC','CALC']\n",
    "].astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_x=df_data.drop(['NObeyesdad'],axis=1)\n",
    "df_y=df_data.loc[:,'NObeyesdad']\n",
    "\n",
    "x = pd.get_dummies(df_x)\n",
    "y = pd.get_dummies(df_y)\n",
    "\n",
    "x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#資料前處理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 21)]              0         \n",
      "_________________________________________________________________\n",
      "nl1 (Dense)                  (None, 32)                704       \n",
      "_________________________________________________________________\n",
      "nl2 (Dense)                  (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "nl3 (Dense)                  (None, 10)                170       \n",
      "_________________________________________________________________\n",
      "nl4 (Dense)                  (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 7)                 77        \n",
      "=================================================================\n",
      "Total params: 1,589\n",
      "Trainable params: 1,589\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "input_layer = Input(shape=(x_train.shape[1],))\n",
    "dense_layer_1 =Dense(32,kernel_initializer=tf.keras.initializers.GlorotNormal() ,activation='relu', name =\"nl1\" )(input_layer)\n",
    "dense_layer_2 = Dense(16,kernel_initializer=tf.keras.initializers.GlorotNormal(),activation='relu', name =\"nl2\" )(dense_layer_1)\n",
    "dense_layer_2 = Dense(10,activation='relu', name =\"nl3\" )(dense_layer_2)\n",
    "dense_layer_2 = Dense(10,activation='relu', name =\"nl4\" )(dense_layer_2)\n",
    "dense_layer_2 = Dropout(0.5)(dense_layer_2)\n",
    "output = Dense(y_train.shape[1],activation='softmax')(dense_layer_2)\n",
    "model = Model(inputs=input_layer, outputs=output)\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "338/338 [==============================] - 1s 598us/step - loss: 2.4341 - precision: 0.0570 - recall: 0.0052 - accuracy: 0.0000e+00 \n",
      "WARNING:tensorflow:Early stopping conditioned on metric `acc` which is not available. Available metrics are: loss,precision,recall,accuracy\n",
      "Epoch 2/50\n",
      "338/338 [==============================] - 0s 543us/step - loss: 1.9071 - precision: 0.2117 - recall: 0.0013 - accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `acc` which is not available. Available metrics are: loss,precision,recall,accuracy\n",
      "Epoch 3/50\n",
      "338/338 [==============================] - 0s 539us/step - loss: 1.8023 - precision: 0.4566 - recall: 0.0138 - accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `acc` which is not available. Available metrics are: loss,precision,recall,accuracy\n",
      "Epoch 4/50\n",
      "338/338 [==============================] - 0s 530us/step - loss: 1.6920 - precision: 0.5833 - recall: 0.0499 - accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `acc` which is not available. Available metrics are: loss,precision,recall,accuracy\n",
      "Epoch 5/50\n",
      "338/338 [==============================] - 0s 530us/step - loss: 1.4769 - precision: 0.5363 - recall: 0.0884 - accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `acc` which is not available. Available metrics are: loss,precision,recall,accuracy\n",
      "Epoch 6/50\n",
      "338/338 [==============================] - 0s 521us/step - loss: 1.2983 - precision: 0.6474 - recall: 0.1535 - accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `acc` which is not available. Available metrics are: loss,precision,recall,accuracy\n",
      "Epoch 7/50\n",
      "338/338 [==============================] - 0s 568us/step - loss: 1.2492 - precision: 0.5861 - recall: 0.1739 - accuracy: 8.8328e-05\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `acc` which is not available. Available metrics are: loss,precision,recall,accuracy\n",
      "Epoch 8/50\n",
      "338/338 [==============================] - 0s 550us/step - loss: 1.1899 - precision: 0.6611 - recall: 0.2174 - accuracy: 0.0018   \n",
      "WARNING:tensorflow:Early stopping conditioned on metric `acc` which is not available. Available metrics are: loss,precision,recall,accuracy\n",
      "Epoch 9/50\n",
      "338/338 [==============================] - 0s 553us/step - loss: 1.1096 - precision: 0.7094 - recall: 0.2947 - accuracy: 0.0036\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `acc` which is not available. Available metrics are: loss,precision,recall,accuracy\n",
      "Epoch 10/50\n",
      "338/338 [==============================] - 0s 541us/step - loss: 1.1494 - precision: 0.6591 - recall: 0.2447 - accuracy: 0.0058   \n",
      "WARNING:tensorflow:Early stopping conditioned on metric `acc` which is not available. Available metrics are: loss,precision,recall,accuracy\n",
      "Epoch 11/50\n",
      "338/338 [==============================] - 0s 536us/step - loss: 1.1742 - precision: 0.6596 - recall: 0.2673 - accuracy: 0.0106\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `acc` which is not available. Available metrics are: loss,precision,recall,accuracy\n",
      "Epoch 12/50\n",
      "338/338 [==============================] - 0s 527us/step - loss: 1.0468 - precision: 0.7230 - recall: 0.3191 - accuracy: 0.0135\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `acc` which is not available. Available metrics are: loss,precision,recall,accuracy\n",
      "Epoch 13/50\n",
      "338/338 [==============================] - 0s 556us/step - loss: 1.0349 - precision: 0.7581 - recall: 0.3378 - accuracy: 0.0173\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `acc` which is not available. Available metrics are: loss,precision,recall,accuracy\n",
      "Epoch 14/50\n",
      "338/338 [==============================] - 0s 524us/step - loss: 0.9618 - precision: 0.7625 - recall: 0.4176 - accuracy: 0.0221\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `acc` which is not available. Available metrics are: loss,precision,recall,accuracy\n",
      "Epoch 15/50\n",
      "338/338 [==============================] - 0s 533us/step - loss: 1.0025 - precision: 0.7254 - recall: 0.3622 - accuracy: 0.0280\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `acc` which is not available. Available metrics are: loss,precision,recall,accuracy\n",
      "Epoch 16/50\n",
      "338/338 [==============================] - 0s 518us/step - loss: 0.9743 - precision: 0.7780 - recall: 0.3900 - accuracy: 0.0318\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `acc` which is not available. Available metrics are: loss,precision,recall,accuracy\n",
      "Epoch 17/50\n",
      "338/338 [==============================] - 0s 526us/step - loss: 1.0094 - precision: 0.7529 - recall: 0.3625 - accuracy: 0.0282\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `acc` which is not available. Available metrics are: loss,precision,recall,accuracy\n",
      "Epoch 18/50\n",
      "338/338 [==============================] - 0s 531us/step - loss: 0.9487 - precision: 0.7548 - recall: 0.3590 - accuracy: 0.0438\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `acc` which is not available. Available metrics are: loss,precision,recall,accuracy\n",
      "Epoch 19/50\n",
      "338/338 [==============================] - 0s 577us/step - loss: 1.0295 - precision: 0.7537 - recall: 0.3411 - accuracy: 0.0430\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `acc` which is not available. Available metrics are: loss,precision,recall,accuracy\n",
      "Epoch 20/50\n",
      "338/338 [==============================] - 0s 527us/step - loss: 0.9472 - precision: 0.7209 - recall: 0.3933 - accuracy: 0.0464   \n",
      "WARNING:tensorflow:Early stopping conditioned on metric `acc` which is not available. Available metrics are: loss,precision,recall,accuracy\n",
      "Epoch 21/50\n",
      "338/338 [==============================] - 0s 530us/step - loss: 0.9444 - precision: 0.7481 - recall: 0.3876 - accuracy: 0.0478\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `acc` which is not available. Available metrics are: loss,precision,recall,accuracy\n",
      "Epoch 22/50\n",
      "338/338 [==============================] - 0s 536us/step - loss: 0.9549 - precision: 0.7782 - recall: 0.3809 - accuracy: 0.0458\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `acc` which is not available. Available metrics are: loss,precision,recall,accuracy\n",
      "Epoch 23/50\n",
      "338/338 [==============================] - 0s 524us/step - loss: 0.9253 - precision: 0.7814 - recall: 0.4046 - accuracy: 0.0646\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `acc` which is not available. Available metrics are: loss,precision,recall,accuracy\n",
      "Epoch 24/50\n",
      "338/338 [==============================] - 0s 532us/step - loss: 0.9529 - precision: 0.7740 - recall: 0.3858 - accuracy: 0.0570\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `acc` which is not available. Available metrics are: loss,precision,recall,accuracy\n",
      "Epoch 25/50\n",
      "338/338 [==============================] - 0s 539us/step - loss: 0.9376 - precision: 0.7673 - recall: 0.4018 - accuracy: 0.0641\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `acc` which is not available. Available metrics are: loss,precision,recall,accuracy\n",
      "Epoch 26/50\n",
      "338/338 [==============================] - 0s 547us/step - loss: 0.9123 - precision: 0.7307 - recall: 0.4056 - accuracy: 0.0851\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `acc` which is not available. Available metrics are: loss,precision,recall,accuracy\n",
      "Epoch 27/50\n",
      "338/338 [==============================] - 0s 533us/step - loss: 0.9199 - precision: 0.7439 - recall: 0.3979 - accuracy: 0.0792\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `acc` which is not available. Available metrics are: loss,precision,recall,accuracy\n",
      "Epoch 28/50\n",
      "338/338 [==============================] - 0s 530us/step - loss: 0.9280 - precision: 0.7894 - recall: 0.4175 - accuracy: 0.0724\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `acc` which is not available. Available metrics are: loss,precision,recall,accuracy\n",
      "Epoch 29/50\n",
      "338/338 [==============================] - 0s 524us/step - loss: 0.8825 - precision: 0.7793 - recall: 0.4173 - accuracy: 0.0755\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `acc` which is not available. Available metrics are: loss,precision,recall,accuracy\n",
      "Epoch 30/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "338/338 [==============================] - 0s 518us/step - loss: 0.9190 - precision: 0.7785 - recall: 0.4123 - accuracy: 0.0764\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `acc` which is not available. Available metrics are: loss,precision,recall,accuracy\n",
      "Epoch 31/50\n",
      "338/338 [==============================] - 0s 553us/step - loss: 0.8726 - precision: 0.8018 - recall: 0.4458 - accuracy: 0.0869\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `acc` which is not available. Available metrics are: loss,precision,recall,accuracy\n",
      "Epoch 32/50\n",
      "338/338 [==============================] - 0s 567us/step - loss: 0.8710 - precision: 0.7782 - recall: 0.4360 - accuracy: 0.1005\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `acc` which is not available. Available metrics are: loss,precision,recall,accuracy\n",
      "Epoch 33/50\n",
      "338/338 [==============================] - 0s 532us/step - loss: 0.8646 - precision: 0.7512 - recall: 0.4419 - accuracy: 0.0969\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `acc` which is not available. Available metrics are: loss,precision,recall,accuracy\n",
      "Epoch 34/50\n",
      "338/338 [==============================] - 0s 530us/step - loss: 0.9382 - precision: 0.7516 - recall: 0.3853 - accuracy: 0.0903\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `acc` which is not available. Available metrics are: loss,precision,recall,accuracy\n",
      "Epoch 35/50\n",
      "338/338 [==============================] - 0s 521us/step - loss: 0.8599 - precision: 0.7834 - recall: 0.4626 - accuracy: 0.0922\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `acc` which is not available. Available metrics are: loss,precision,recall,accuracy\n",
      "Epoch 36/50\n",
      "338/338 [==============================] - 0s 521us/step - loss: 0.8643 - precision: 0.7915 - recall: 0.4731 - accuracy: 0.1013\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `acc` which is not available. Available metrics are: loss,precision,recall,accuracy\n",
      "Epoch 37/50\n",
      "338/338 [==============================] - 0s 521us/step - loss: 0.9070 - precision: 0.7349 - recall: 0.4326 - accuracy: 0.1078\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `acc` which is not available. Available metrics are: loss,precision,recall,accuracy\n",
      "Epoch 38/50\n",
      "338/338 [==============================] - 0s 542us/step - loss: 0.8371 - precision: 0.7819 - recall: 0.4602 - accuracy: 0.1089\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `acc` which is not available. Available metrics are: loss,precision,recall,accuracy\n",
      "Epoch 39/50\n",
      "338/338 [==============================] - 0s 518us/step - loss: 0.9497 - precision: 0.7765 - recall: 0.3861 - accuracy: 0.0973\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `acc` which is not available. Available metrics are: loss,precision,recall,accuracy\n",
      "Epoch 40/50\n",
      "338/338 [==============================] - 0s 524us/step - loss: 0.8144 - precision: 0.7800 - recall: 0.4665 - accuracy: 0.1216\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `acc` which is not available. Available metrics are: loss,precision,recall,accuracy\n",
      "Epoch 41/50\n",
      "338/338 [==============================] - 0s 522us/step - loss: 0.8648 - precision: 0.7894 - recall: 0.4546 - accuracy: 0.1249\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `acc` which is not available. Available metrics are: loss,precision,recall,accuracy\n",
      "Epoch 42/50\n",
      "338/338 [==============================] - 0s 524us/step - loss: 0.8474 - precision: 0.7927 - recall: 0.4684 - accuracy: 0.1117\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `acc` which is not available. Available metrics are: loss,precision,recall,accuracy\n",
      "Epoch 43/50\n",
      "338/338 [==============================] - 0s 524us/step - loss: 0.8170 - precision: 0.7856 - recall: 0.4730 - accuracy: 0.1219\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `acc` which is not available. Available metrics are: loss,precision,recall,accuracy\n",
      "Epoch 44/50\n",
      "338/338 [==============================] - 0s 592us/step - loss: 0.8293 - precision: 0.7806 - recall: 0.4515 - accuracy: 0.1147\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `acc` which is not available. Available metrics are: loss,precision,recall,accuracy\n",
      "Epoch 45/50\n",
      "338/338 [==============================] - 0s 565us/step - loss: 0.8287 - precision: 0.7944 - recall: 0.4463 - accuracy: 0.1196\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `acc` which is not available. Available metrics are: loss,precision,recall,accuracy\n",
      "Epoch 46/50\n",
      "338/338 [==============================] - 0s 592us/step - loss: 0.8762 - precision: 0.7980 - recall: 0.4460 - accuracy: 0.1195\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `acc` which is not available. Available metrics are: loss,precision,recall,accuracy\n",
      "Epoch 47/50\n",
      "338/338 [==============================] - 0s 535us/step - loss: 0.8224 - precision: 0.7891 - recall: 0.4815 - accuracy: 0.1301\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `acc` which is not available. Available metrics are: loss,precision,recall,accuracy\n",
      "Epoch 48/50\n",
      "338/338 [==============================] - 0s 532us/step - loss: 0.8756 - precision: 0.7777 - recall: 0.4706 - accuracy: 0.1323\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `acc` which is not available. Available metrics are: loss,precision,recall,accuracy\n",
      "Epoch 49/50\n",
      "338/338 [==============================] - 0s 524us/step - loss: 0.7657 - precision: 0.7987 - recall: 0.4979 - accuracy: 0.1280\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `acc` which is not available. Available metrics are: loss,precision,recall,accuracy\n",
      "Epoch 50/50\n",
      "338/338 [==============================] - 0s 562us/step - loss: 0.8619 - precision: 0.7736 - recall: 0.4580 - accuracy: 0.1306\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `acc` which is not available. Available metrics are: loss,precision,recall,accuracy\n"
     ]
    }
   ],
   "source": [
    "callback = tf.keras.callbacks.EarlyStopping(monitor='acc',mode='max', patience=5)\n",
    "Adam = tf.optimizers.Adam(lr=0.003, beta_1=0.9, beta_2=0.997, epsilon=1e-08, decay=0.0)\n",
    "model.compile(optimizer=Adam, \n",
    "              loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n",
    "              metrics = [tf.keras.metrics.Precision(),tf.keras.metrics.Recall(),tf.keras.metrics.Accuracy()]\n",
    "              )\n",
    "history = model.fit(x=x_train, y=y_train,  epochs=50,batch_size =5, callbacks=[callback] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 0s 614us/step - loss: 0.5950 - precision: 0.8658 - recall: 0.6099 - accuracy: 0.1196\n",
      "[0.5950068831443787, 0.8657718300819397, 0.609929084777832, 0.11955420672893524]\n",
      "0.7156726876441423\n"
     ]
    }
   ],
   "source": [
    "preds = model.evaluate(x = x_test, y = y_test)\n",
    "\n",
    "F1 = 2 * (preds[1] * preds[2]) / (preds[1] + preds[2])\n",
    "print(preds)\n",
    "print(F1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 0s 693us/step - loss: 0.5950 - precision: 0.8658 - recall: 0.6099 - accuracy: 0.1196\n",
      "Precision 0.8657718300819397\n",
      "Recall} 0.609929084777832\n",
      "F1 0.7156726876441423\n"
     ]
    }
   ],
   "source": [
    "reds = model.evaluate(x = x_test, y = y_test)\n",
    "\n",
    "F1 = 2 * (preds[1] * preds[2]) / (preds[1] + preds[2])\n",
    "print('Precision', preds[1])\n",
    "print('Recall}', preds[2])\n",
    "print('F1',F1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeMAAAEzCAYAAAACSWsXAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOzdd3xUVf7/8deZSe+9kB5aAqmQUAQxoKKAFVF0UQHb17ruqmvb9eeq26yrLrrKWpBdFSu7FkBFCE06hBoSQhJIQkgI6aRP7u+PG0JLyAQmmZTP8/G4j2l37px7CfOec+655yhN0xBCCCGE9RisXQAhhBCiv5MwFkIIIaxMwlgIIYSwMgljIYQQwsokjIUQQggrkzAWQgghrKzDMFZKhSilViql0pVSe5RSD7exTopSqkIplday/L+uKa4QQgjR99iYsU4T8KimaduUUq7AVqXUT5qm7T1jvTWapl1l+SIKIYQQfVuHNWNN0wo1TdvWcr8KSAeCurpgQgghRH/RqXPGSqlwIBHY2MbLY5VSO5RSS5VSwy1QNiGEEKJfMKeZGgCllAvwFfAbTdMqz3h5GxCmaVq1Umoq8F9gcBvbuAe4B8DR0XFkSEjIeRf8TM3NzRgM0h/NEuRYWo4cS8uRY2k5ciwtp7PHMjMzs0TTNN8zn1fmjE2tlLIFvgN+0DTtNTPWzwWSNE0raW+dpKQkbcuWLR1+trlSU1NJSUmx2Pb6MzmWliPH0nLkWFqOHEvL6eyxVEpt1TQt6cznzelNrYD3gfT2glgpFdCyHkqpUS3bPWZ26YQQQoh+zJxm6nHAbcAupVRay3NPA6EAmqa9A8wA7lNKNQG1wM2aTAclhBBCmKXDMNY0bS2gOlhnHjDPUoUSQggh+hOzO3AJIYToHxobG8nPz6eurs7aRenx3N3dSU9PP+t5BwcHgoODsbW1NWs7EsZCCCFOk5+fj6urK+Hh4bR0BxLtqKqqwtXV9bTnNE3j2LFj5OfnExERYdZ2pG+7EEKI09TV1eHt7S1BfJ6UUnh7e3eqZUHCWAghxFkkiC9MZ4+fhLEQQogex8XFxdpF6FYSxkIIIYSVSRgLIYTosTRN43e/+x0xMTHExsby2WefAVBYWMiECRNISEggJiaGNWvWYDKZmDNnTuu6f//7361cevNJb2ohhBA91tdff01aWho7duygpKSE5ORkJkyYwCeffMIVV1zB73//e0wmEzU1NaSlpVFQUMDu3bsBKC8vt3LpzSdhLIQQol3PfbuHvYfPnBvowgwb4MazV5s3ud/atWu55ZZbMBqN+Pv7c8kll7B582aSk5O54447aGxs5LrrriMhIYHIyEiys7N56KGHmDZtGpMnT7ZoubuSNFMLIYTosdobWXnChAmsXr2aoKAgbrvtNhYuXIinpyc7duwgJSWFt956i7vuuqubS3v+pGYshBCiXebWYLvKhAkTePfdd5k9ezalpaWsXr2al19+mYMHDxIUFMTdd9/N8ePH2bZtG1OnTsXOzo4bbriBgQMHMmfOHKuWvTMkjIUQQvRY119/PevXryc+Ph6lFC+99BIBAQF89NFHvPzyy9ja2uLi4sLChQspKChg7ty5NDc3A/DXv/7VyqU3n4SxEEKIHqe6uhrQB894+eWXefnll097ffbs2cyePfus923btq1bymdpcs5YCCGEsDIJYyGEEMLKJIyFEEIIK5MwFkIIIaxMwlgIIYSwMgljIYQQwsokjIUQQvQLW7Zs4de//nW7rx8+fJgZM2Z0Y4lOkuuMhRBC9Eomkwmj0Wj2+klJSSQlJbX7+oABA/jyyy8tUbROk5qxEEKIHic3N5eoqChmz55NXFwcM2bMoKamhvDwcJ5//nnGjx/PF198wY8//sjYsWMZMWIEN954Y+tgIZs3b+aiiy4iPj6eUaNGUVVVRWpqKldddRUAq1atIiEhgYSEBBITE6mqqiI3N5eYmBgA6urqmDt3LrGxsSQmJrJy5UoAFixYwPTp07nyyisZPHgwzzzzjEX2V2rGQggheqSMjAzef/99xo0bxx133MHbb78NgIODA2vXrqWkpITp06ezfPlynJ2defHFF3nttdd48sknmTlzJp999hnJyclUVlbi6Oh42rZfeeUV3nrrLcaNG0d1dTUODg6nvf7WW28BsGvXLvbt28fkyZPJzMwEIC0tje3bt2Nvb8+QIUN49NFHCQkJuaB9lTAWQgjRvqVPwpFdlt1mQCxM+VuHq4WEhDBu3DgAbr31Vt58800AZs6cCcCGDRvYu3dv6zoNDQ2MHTuWjIwMAgMDSU5OBsDNze2sbY8bN45HHnmEWbNmMX36dIKDg097fe3atTz00EMAREVFERYW1hrGl156Ke7u7gAMHTqUgwcPShgLIYTom5RSbT52dnYG9OkVL7/8cj799NPT1tu5c+dZ7z3Tk08+ybRp01iyZAljxoxh+fLlp9WO25u6EcDe3r71vtFopKmpybwdOgcJYyGEEO0zowbbVQ4dOsT69esZO3Ysn376KePHj2f79u2tr48ZM4YHHniArKwsBg0aRE1NDfn5+URFRXH48GE2b95McnIyVVVVZzVTHzhwgNjYWGJjY1m/fj379u0jISGh9fUJEybw8ccfM2nSJDIzMzl06BBDhw7tsokopAOXEEKIHik6OpqPPvqIuLg4SktLue+++0573dfXlwULFnDLLbcQFxfHmDFj2LdvH3Z2dnz22Wc89NBDxMfHc/nll1NXV3fae19//XViYmKIj4/H0dGRKVOmnPb6/fffj8lkIjY2lpkzZ7JgwYLTasSWJjVjIYQQPZLBYOCdd9457bnc3NzTHk+aNInNmzef9d7k5GQ2bNhw2nMpKSmkpKQA8I9//OOs94SHh7N7925A7yS2YMGCs9aZM2cOc+bMaX38xRdf4OrqasbenJvUjIUQQggrkzAWQgjR45xaS+0PJIyFEEIIK5MwFkIIIaxMwlgIIYSwMgljIYQQwsokjIUQQvQLCxYs4MEHHwTgj3/8I6+88oqVS3SShLEQQogeTdM0mpubrV2MLiVhLIQQosfJzc0lOjqa+++/nxEjRvDCCy+QnJxMXFwczz77bOt6CxcuJC4ujvj4eG677TYAvv32W0aPHk1iYiKXXXYZRUVF1toNs8kIXEIIIXqkjIwMPvzwQ6677jq+/PJLNm3ahKZpXHPNNaxevRpvb2/+/Oc/s27dOnx8fCgtLQVg/PjxbNiwAaUU7733Hi+99BKvvvqqlffm3CSMhRBCtOvFTS+yr3SfRbcZ5RXFE6Oe6HC9sLAwxowZw2OPPcaPP/5IYmIiANXV1ezfv58dO3YwY8YMfHx8APDy8gIgPz+fmTNnUlhYSENDAxERERYtf1eQZmohhBA90qlTJT711FOkpaWRlpZGVlYWd955J5qmtTlV4kMPPcSDDz7Irl27ePfdd8+aJKInkpqxEEKIdplTg+1qV1xxBc888wyzZs3CxcWFgoICbG1tufTSS7n++uv57W9/i7e3N6WlpXh5eVFRUUFQUBAAH330kZVLb54+E8bHG9ufCFoIIUTvNXnyZNLT0xk7diwALi4u/Oc//2H48OH8/ve/55JLLsFoNJKYmMiCBQv44x//yI033khQUBBjxowhJyfHynvQMaVp1gmxpKQkbcuWLRbZVmpGMXct2Mx/HxxPTJC7RbbZn6WmprZOMyYujBxLy5FjaTkdHcv09HSio6O7r0C9WFVVVbtTKLZ1HJVSWzVNSzpz3T5xzjgx1BODgo83HrJ2UYQQQohO6xNh7O5oy+hAG/6XVkBVXaO1iyOEEEJ0Sp8IY4CJoTbUNJj4b9phaxdFCCGE6JQOw1gpFaKUWqmUSldK7VFKPdzGOkop9aZSKksptVMpNaJritu+CDcDMUFufLzhINY6Dy6EEEKcD3Nqxk3Ao5qmRQNjgAeUUsPOWGcKMLhluQf4p0VLaQalFLNGh7HvSBXbDpV398cLIYQQ563DMNY0rVDTtG0t96uAdCDojNWuBRZqug2Ah1Iq0OKl7cA18QNwsbfh440Hu/ujhRBCiPPWqeuMlVLhQCKw8YyXgoC8Ux7ntzxXeMb770GvOePv709qamqnCnsu1dXVbF6/llH+8E1aAZM8ynCxO3tkFtGx6upqi/7b9GdyLC1HjqXldHQs3d3dqaqq6r4C9WImk6ndY1VXV2f236zZYayUcgG+An6jaVrlmS+38ZazTtxqmjYfmA/6dcaWvGbwxHVz/kMrWfHGGo44hnHXxZEW235/ItdzWo4cS8uRY2k55lxn3N61s31NU1MTNjbnP/7Vua4zdnBwaB1PuyNm9aZWStmiB/HHmqZ93cYq+UDIKY+DAat0a44OdGNkmCefbDwkHbmEEKIXu+666xg5ciTDhw9n/vz5ACxbtowRI0YQHx/PpZdeCug1/blz5xIbG0tcXBxfffUVoI/UdcKXX37JnDlzAJgzZw6PPPIIEydO5IknnmDTpk1cdNFFJCYmctFFF5GRkQHotd7HHnusdbv/+Mc/+Pnnn7n++utbt7tixQqmT59+wfva4c8BpY/C/T6Qrmnaa+2s9g3woFJqETAaqNA0rbCddbvcrNGhPPL5DtZnH+OigT7WKoYQQogL8MEHH+Dl5UVtbS3Jyclce+213H333axevZqIiIjWKRNfeOEF3N3d2bVrFwBlZWUdbjszM5Ply5djNBqprKxk9erV2NjYsHz5cp5++mm++uor5s+fT05ODtu3b8fGxobS0lI8PT154IEHOHr0KL6+vvznP/9h7ty5F7yv5tTNxwG3AbuUUmktzz0NhAJomvYOsASYCmQBNcCFl+wCTI0N5Pnv9vLxxkMSxkIIcQGO/OUv1KdbdgpF++goAp5+usP13nzzTRYvXgxAXl4e8+fPZ8KECa1TIp6YMnH58uUsWrSo9X2enp4dbvvGG2/EaDQCUFFRwezZs9m/fz9KKRobG1u3e++997Y2Y5/4vNtuu601hDdv3synn35q7q63q8Mw1jRtLW2fEz51HQ144IJLYyEOtkZmjAhmwS+5HK2qx9fV3tpFEkII0QmpqaksX76c9evX4+TkREpKCvHx8a1NyKdqbyrFU587cxrFE9MzAjzzzDNMnDiRxYsXk5ub23o+vb3tzp07l6uvvhoHBweuu+66CzrnfEKfmbXpTL8aHcp7a3P4fEseD0wcZO3iCCFEr2RODbYrVFRU4OnpiZOTE/v27WPDhg3U19ezatUqcnJyWpupvby8mDx5MvPmzeP1118H9GZqT09P/P39SU9PZ+jQoSxevLjdjlanTrm4YMGC1ucnT57MO++8Q0pKSmsztZeXFwMGDGDAgAH86U9/4r///a9F9rfPDId5pkhfF8YN8ubTTYcwNUtHLiGE6E2uvPJKmpqaiIuL45lnnmHMmDH4+voyf/58pk+fTnx8PDNnzgTgD3/4A2VlZcTExBAfH8/KlSsB+Nvf/sZVV13FpEmTCAxsf+iLxx9/nKeeeopx48ZhMplan7/rrrsIDQ0lLi6O+Ph4Pvnkk9bXZs2aRUhICFFRURbZ3z5bMwaYNTqM+z/exurMo0yM8rN2cYQQQpjJ3t6epUuXtvnalClTTnvs4uLCRx99dNZ6M2bMYMaMGWc9f2rtF2Ds2LFkZma2Pn7hhRcAsLGx4bXXXuO1187uu7x27VruvvvuDvfDXH22Zgxw+TB/fF3tZUQuIYQQFjNy5Eh27tzJrbfearFt9umasa3RwMykEN5OzaKgvJYgD0drF0kIIUQvt3Xr1tb7DQ0NFtlmn64ZA9w8KgQN+GzTIWsXRQghhGhTnw/jYE8nJg71Y9HmPBpNzdYujhBC9AoyguGF6ezx6/NhDPqIXMVV9SzbfcTaRRFCiB7PwcGBY8eOSSCfJ03TOHbsGA4ODma/p0+fMz4hZagfQ/xd+P3iXUQFuDLYv38MgC6EEOcjODiY/Px8jh49au2i9Hh1dXVthq6DgwPBwcFmb6dfhLHRoHh/djLT//kLsz/YxNf3jyPA3fxfLEII0Z/Y2tq2Djkpzi01NdXsmZnOpV80UwOEeDmxYG4yFbWNzPlwE5V1jdYukhBCCAH0ozAGGD7AnXduG0lWcTX3/nsrDU3SoUsIIYT19aswBrh4sC8vzYjjlwPH+N2XO2iWoTKFEEJYWb84Z3ym6SOCKayo4+UfMghwc+CpqdHWLpIQQoh+rF+GMcD9KQM5UlHHu6uzCXB3YO446awghBDCOvptGCul+OM1wymqrOP57/YS4ObAlNj2Z/UQQgghukq/O2d8KqNB8eYtiYwI9eThz9LYlFNq7SIJIYToh/p1GAM42Bp57/Ykgj0d+fWn26lrNHX8JiGEEMKC+n0YA3g62/GX62M5UlnHv9fLdItCCCG6l4RxizGR3kwY4stbqVkyIIgQQohuJWF8isevGEp5TSPvrc62dlGEEEL0IxLGp4gJcmdabCDvrc2hpLre2sURQgjRT0gYn+GRyUOob2rmrZVZ1i6KEEKIfkLC+AwDfV24cWQwH284RH5ZjbWLI4QQoh+QMG7Dw5cNBgWvL99v7aIIIYToBySM2xDo7sjtY8L4els++4uqrF0cIYQQfZyEcTvunzgIJzsbXv0x09pFEUII0cdJGLfDy9mOuy+OZNmeI6TllVu7OEIIIfowCeNzuPPiCLyd7Xj5h33WLooQQog+TML4HFzsbbh/4iDWZR1jXVaJtYsjhBCij5Iw7sCs0aEMcHfgpWX70DTN2sURQgjRB0kYd8DB1shvLh/CjvwKfthzxNrFEUII0QdJGJthemIQA32deeXHTEzNUjsWQghhWRLGZrAxGnho0mCyiqvZnFtq7eIIIYToYySMzTR5uD8OtgaW7Cq0dlGEEEL0MRLGZnKys2FSlB9Ldh2RpmohhBAWJWHcCdNiB1BSXc+mHGmqFkIIYTkSxp0wMcpXmqqFEEJYnIRxJzjZ2XBplD9Ld0tTtRBCCMuRMO6kqbGB0lQthBDCoiSMO2lilC+Otka+33XY2kURQgjRR0gYd9KJXtXLpKlaCCGEhUgYn4dpcYGUVDewMeeYtYsihBCiD5AwPg8Th/rpTdU7pVe1EEKICydhfB4c7YxMivbjhz1HaDI1W7s4QggherkOw1gp9YFSqlgptbud11OUUhVKqbSW5f9Zvpg9z1WxelO19KoWQghxocypGS8AruxgnTWapiW0LM9feLF6vpSWpurvZAAQIYQQF6jDMNY0bTUg1b8zONoZuTTajx92S1O1EEKIC2Opc8ZjlVI7lFJLlVLDLbTNHm9abCDHjjewUZqqhRBCXAClaR1fK6uUCge+0zQtpo3X3IBmTdOqlVJTgTc0TRvcznbuAe4B8Pf3H7lo0aILKPrpqqurcXFxsdj2zFFv0vj1ihrGBtowJ8a+Wz+7K1njWPZVciwtR46l5cixtJzOHsuJEydu1TQt6cznbS60IJqmVZ5yf4lS6m2llI+maSVtrDsfmA+QlJSkpaSkXOjHt0pNTcWS2zPX5OLtrMsqYfzFE7Ax9o3O6dY6ln2RHEvLkWNpOXIsLcdSx/KC00MpFaCUUi33R7Vss9+MhjEtNoDS4w1syJamaiGEEOenw5qxUupTIAXwUUrlA88CtgCapr0DzADuU0o1AbXAzZo5bd99RMpQP5zsjHy/q5Dxg32sXRwhhBC9UIdhrGnaLR28Pg+YZ7ES9TIOtkYujfZn2e5CXrh2eJ9pqhZCCNF9JDksYFpsIGU1jazP7jet80IIISxIwtgCUob64mxnZIkMACKEEOI8SBhbwMmm6iM0ygAgQgghOknC2EKmtjRVr91/1hVdQgghxDlJGFtIylBfBrg78OpPGTQ395vO5EIIISxAwthCHGyNPH5lFLsLKlm8vcDaxRFCCNGLSBhb0DXxA4gLduflHzKobTBZuzhCCCF6CQljCzIYFH+YNowjlXX8a022tYsjhBCil5AwtrBREV5cOTyAd1YdoLiyztrFEUII0QtIGHeBJ6dE0Whq5rWfMq1dFCGEEL2AhHEXCPdx5vax4Xy2JY/0wsqO3yCEEKJfkzDuIg9NGoSbgy1//j6dfjRvhhBCiPMgYdxFPJzsePjSwazNKiE146i1iyOEEKIHkzDuQreOCSPc24k/L0mnSYbJFEII0Q4J4y5kZ2PgySnRZBVXs2hznrWLI4QQooeSMO5iVwz3Z1SEF3//KZOqukZrF0cIIUQPJGHcxZRS/GFaNMeON/B26gFrF0cIIUQPJGHcDeKCPZieGMT7a3PIK62xdnGEEEL0MBLG3eSxK4aigLsXbmFXfoW1iyOEEKIHkTDuJgM8HHl71ghKjzdw7Vtref7bvVTXN1m7WEIIIXoACeNudGm0P8sfvYRZo8P48JccLn9tFT/uOWLtYgkhhLAyCeNu5uZgywvXxfDlvRfh7mjLPf/eyj0Lt1BYUWvtogkhhLASCWMrGRnmybcPjeeJK6NYvf8ol726ig/X5WBqlqEzhRCiv5EwtiJbo4H7Ugby428uYWS4F899u5eZ766X65GFEKKfkTDuAUK9nfhobjKv3hhPWl45dy/cQl2jydrFEkII0U0kjHsIpRQ3jAzm1Zvi2ZhTyoOfbKNRxrMWQoh+QcK4h7k2IYjnrhnO8vRinvhyJ81yDlkIIfo8G2sXQJzt9rHhVNQ08upPmbg52vLs1cNQSlm7WEIIIbqIhHEP9eCkQVTUNvLe2hzcHW357eVDrF0kIYQQXUTCuIdSSvH7adFU1Dbyxs/7cXe05Y7xEdYulhBCiC4gYdyDKaX46/RYKusaef67vbg72nLDyGBrF0sIIYSFSQeuHs7GaOCNmxMZN8ibx7/aKcNnCiFEHyRh3As42BqZf1sSsUHuPPjJdv703V6KKuusXSwhhBAWImHcSzjb27BgbjJXxQXy4S+5XPziSv7w310yP7IQQvQBEsa9iIeTHa/NTGDloyncMDKYzzbnMfGVVB79fAcHjlZbu3hCCCHOk4RxLxTq7cRfp8ey+vGJ3DY2jO93Heay11bxwCfb2Hu48oK2rWkazZoMNCKEEN1JelP3YoHujjx79XAemDiI99fm8O/1B/l+ZyGB7g6EeDoR4uVEiJcjoV4t9z2d8HO1B6Coqo7ckhoOHjvOwVL9NrekhkOlNRi0JhYNrWTYADcr76EQQvQPEsZ9gI+LPU9cGcW9Ewby+ZY80o9Ukldaw7qsEoqq6ji1omtnY0AB9U0nx722NSpCPJ0I9XZiVIQX32w7yB0LNrP4gYsIdHfs/h0SQoh+RsK4D3F3suXuCZGnPVffZKKgrJZDpTXkldWSV1qDpmmEeTsT7u1MmLcTge4O2BhPnrEYqIp4cUsjdyzYwhf3jsXFXv5MhBCiK8m3bB9nb2Mk0teFSF8Xs98T4mrgrVkjuGPBZh74eBvvz046LayFEEJYlnzDijZdMsSXP10Xw6rMozzzvz1o0qlLCCG6jNSMRbtuGRVKXmkNb6ceIMzbiXsvGWjtIgkhRJ8kYSzO6bHJQ8krq+VvS/cR7OnIVXEDrF0kIYTocySMxTkZDIqXZ8RRWF7LI5/vIMDNgaRwL2sXSwgh+hQ5Zyw65GBrZP7tSQR5OHL3wi3klBy3dpGEEKJP6bBmrJT6ALgKKNY0LaaN1xXwBjAVqAHmaJq2zdIFFdbl5WzHh3OSuf7tdcz5cBM3jgzGaDBgY1AYDQobo8LmlMdjBnoT5CHXKAshhDnMaaZeAMwDFrbz+hRgcMsyGvhny63oY8J9nHlvdhJ3LNjCKz9mnnNdVwcbXrspgcuH+Z/XZ2mahv477/w0NDWjFNjKJVlCiF6gwzDWNG21Uir8HKtcCyzU9GtfNiilPJRSgZqmFVqojKIHGRnmxfZnLsekaZiaNZqaNUwmjabm5tbHZTUNPPnVLu5euIX7Uwby6OShGA3mBWt5TQN/W7qPr7blM8TflXGDfBg70JtR4V44n2PwEVOzxt7DlazNKuGXAyVsyinF0c7IjSODmTU6jHAfZ0sdAiGEsDhLdOAKAvJOeZzf8pyEcR9lMCgMKGyNbb8+wMORL+4dy3Pf7uHt1APsyC/nzZsT8Xaxb3ebmqbx9bYC/rwknYraRq5NGEBBWS0L1uUyf3U2NgZFfIgH4wZ6M3agD4mhHhRW1LEuq4R1WSWszz5GeU0jAEP9XfnV6FCKKuv4cF0u/1qTw8WDfZg1OozLov1kABMhRI+jzBnMoaVm/F0754y/B/6qadralsc/A49rmra1jXXvAe4B8Pf3H7lo0aILKvypqqurcXExf5Qp0T5LHss1+Y18tLcBNzvFAwn2DPQ4O8EPVzezcG89+0qbGehuYPZwO0Ld9PXqTRpZZc2kl5rYe8xETkUzGmBQ0Nzyp+vloBjubWSYt5FobwMe9ifDtryumVX5TazKb6K0TsPTXnFJiA2XBNvg6aCv12DSKKnVKK5ppqjm5G15XTPDvY1MCLYlyPX8Alz+Li1HjqXlyLG0nM4ey4kTJ27VNC3pzOctEcbvAqmapn3a8jgDSOmomTopKUnbsmWLeaU3Q2pqKikpKRbbXn9m6WO5u6CC+z7eypGKOv7fVcO4dUwYSinqGk28tTKLd1YdwNHWyJNTork5OQTDOZq0K+sa2ZxTyubcMoI8HRk/yIdwb6cOzy83mZpZsa+Y/2w8xOrMoxgNirhgd4or6zlcUXvaZBquDjaEezvj7mjLxpxjNJo0EkI8mJkcwlVxgbg62Jq97/J3aTlyLC1HjqXldPZYKqXaDGNLNFN/AzyolFqE3nGrQs4Xi1PFBLnz3YMX85vPtvPM//aw7VA502IDeeH7vRw8VsP0xCCemhqNr2v7zdgnuDnYcmm0P5dGd65jmI3RwOThAUweHkBuyXE+2XSI7YfKSA73JMw7mHAfp9bJMzydbFvD/Vh1PYu3F/D5ljye+noXz3+7l2lxgcxMDiEpzPOCOpkJIcQJ5lza9CmQAvgopfKBZwFbAE3T3gGWoF/WlIV+adPcriqs6L3cnWx5f3Yy81Zm8fflmSzeXkCkjzOf3DWaiwb5dGtZwn2ceXpqtFnrervYc9fFkdw5PoK0vHI+35LHN2mH+XJrPpE+zgwPcseo9B3iz58AACAASURBVPPoJy7rMij9vsGgqClpZEhCLQPkMi8hxDmY05v6lg5e14AHLFYi0WcZDIpfXzqYpDBP9h2pYtaYUOxt2ukF1sMopUgM9SQx1JNnrhrG9zsL+WpbPrsLKjA1aycXTaO55dZk0qiqb+LzF1cwOsKL6YnBTIkN6FQztxCif5DhMEW3u2iQT7fXhi3Jyc6GG5NCuDEppMN1P1+ygiP2ISzeXsDjX+3kmf/t5vJh/lyfGMSEIb5mXQfd0NRMSXU9xVX1FFfWcbS6nuLKeo5W13O0qh4nOyMxA9wZPsCN4QPccXeSsBeit5EwFqIL+TkZuCllMA9NGkRaXjmLtxfw7Y7DfLezEG9nOyZF+WE0KI43mKipb+J4QxO1DabWx9X1TVTWNbW5bW9nO3xd7amsbeR/aYdbnw/2dGwN55ggdwb6uuBga8DORl9sjfpIaed7vlvTNBpNGvVNJuqbmqlrNOHhZIfLOa4DF0Kcm/zvEaIbnNrM/Ydpw1ideZTF2wv4Kb0IO6MBZ3sbnOyMONvZ4OlsR7Cn/tjJzoi3iz2+rvb4uZ64dcDbxe60WvWx6nr2HK5kz+FKdh+uYO/hSpbtOXKO8oCdsSWgjQaUUiilXzKm0O+rlnIrBU0mjbomE/WNzdQ3mVovKzvBxd6GeyZEctfFETjZde5rZXdBBV9uzSc53IupsQHSKU70SxLGQnQzOxsDlw3z57LzHCq0Ld4u9kwY4suEIb6tz1XVNZJeWEXuseM0NDXri0m/bWy5rW+5r4erhqZBs6bfatByq2FrMGBva8DexoCDrRF7GwP2NsbWGvfP6cW89lMm/95wkN9cNpiZSSEdDq6y7VAZ81ZksWJfMQYFC37JJS7YnSeujGJcN5/GKK9pYEP2MWKDPWRMdWEVEsZC9FGuDraMivBiVETXT3k5MzmULbml/HXpPn6/eDfvr83h8SuiuGK4/1k13Q3Zx5i3Iou1WSV4Otny2OQh3DomjJ/2FvH3nzKZ9d5GLh7sw+NXRBEb7N5lZc4vq+GnvUX8tLeIjTmlmJo1XB1s+PtNCRb9oSSEOSSMhRAWkRTuxZf3juWnvUW8uGwf9/5nKyPDPHlqShQjwzxZs7+EeSuy2JRbio+LPb+fGs2vRoe2jjl+Y1IIV8cP4D8bDvLWyiyunreWaXGBPDZ5KBEWGFtc0zTSC6v4ce8RftxTxN7CSgAG+7nwfxMiGRXhxSs/ZnDXwi08MHEgj1xu/pjqQlwoCWMhhMUopZg8PIBJUX58sTWfv/+UyYx31hPs6Uh+WS2B7g48d81wZiaH4NDG4OYOtkbuujiSm5JD+NfqbN5bk8Oy3UeYmRyCX2MTZdvzKa9ppLymkYraRsprGiiv1R8fr9c7up16OvvUEQar6poorqpHKRgZ6snTU6O4fFjAaUE/JtKbZ/+3h7dWHmBHXgVv3JxwzjHVzXXw2HFW7itmY04pzvY2BHs6EuLppN96OeHv5iDB389JGAshLM7GaOCWUaFcmzCAD9flsirzKA9MHMQNI4Kxs+n4ci43B1senTyU28aGMW9FFp9sPERTswbbdpyyjg0eTnZ4ONni7mhLgJsDhlM2rVAn7gB6h7UxkV5MivJvd7Q3B1sjL86IY0SYB8/8bw9X/WMtb88aQWKoZ6f2v77JxKacUlbuO0pqRjHZJccBvad7o6mZosr609a3NSoGeDgS7OlIhI8zQ/1dGeLvytAAVzyc7Dr12ebSNP06+CMVdRRW1FHUcnukshZXB1smD/NnRKjnOYenFZYjYSyE6DJOdjY8MHEQD0wcdF7v93N14PlrY7gvZSDfr/yFS8ePwcPRFjdH2y6tSc5MDmVYoDv3fbyVm95df9qY6m05Xt9EVnE1OwsqWJVRzLqsY9Q2mrCzMTA20pvbx4aRMtSvdSrP+iYTh8vryCutIb+slryyltvSGv6XdpiqUy5n83O1Z2hASzj7u5IQ6sEQf9fz2q+tB8t4b00223NqqFzxAzUNprPW8XGxo7K2ifmrs/F1tWfyMH+ujAlgTKS3zA/ehSSMhRA9XqC7I4M8jBY5d2yu2GB3vntoPL/5LK11TPUnp0SRX1bD/qJq9hfry4HiagrKa1vfF+zpyI1JwUwc6seYSG8c7c5ujre30felrf3RNI0jlXVkHKlif1E1GUVVZBZV8fHGg9Q1NgMwKtyLuePCuXyYv1lTgm7OLeXNn/ezZn8JXs52DHQ1EDswlEB3BwJOLG4O+LnZY29jpLKukZX7ivlxTxGLtxfw8cZDuDnYcFm0P1fEBDBhsG+b+9VTbDtUxn/WH+SahAGkDPU7r21omkZ2yXEG+nbP7FYSxkII0Q4PJzs+mJ3MP1Zk8frP+pjqJzjYGhjk50JyuCe/8g9loK8LUQGuhJkxi9i5KKUIdHck0N3xtCAxNWvkldawPL2Ij9bnct/H2wjycOS2sWHcnBzSZnP2huxjvPnzfn45cAwfFzuenhrFrNFhbF6/lpSUYe2Wwc3BlmsTgrg2IYi6RhNr9pewbPcRlqcX8fX2AuxsDMQGuTMyzJMRoR6MCPXEz82h3e01mprJOFLFjvxyduZVsKuggiH+LvzuyiiLXUqmaRobskuZt3I/67KOAfD9rkL+fefoTl9RoGkaz36zhy+25LP04YtbWzS6koSxEEKcg8GgePiywYyJ9GJnfgWD/FwY5OdCkIdjt55PNRoU4T7O3HVxJHPHRfBzehEfrsvlb0v38fryTK5PDGbuuHAG+7mwPvsYbyzfz8acUnxd7fnDtGhmjQ47r9qsg62Ry4f5c/kwfxpNzWzMLiU1o5hth8pYsC6X+av12nqQhyMjWsJ5+AB38stq2JlfwY78cvYcrqShSV/Pw8mWYYFuLN19hKW7j/B/lwzk3ksiOz1YzAmaprEq8yjzVmSx5WAZPi72PD01iikxgcz+cBN3frSZz/9vLNGBbmZv77lv97Jw/UHuvjiCMG+n8ypXZ0kYCyGEGUZHejM60tvaxQD0YD4xJWh6YSUL1uXy9bZ8Pt10iFAvJw6V1uDnas+zVw/jllGhbfZcPx+2RgPjB/swfrA+KEt9k4k9hyvZdrCM7YfK2ZJbyrc7Tg7N6mRnJCbIndljw4gL9iA+2IMQL0eUUuSX1fC3pft48+f9fLEljyenRHFN/ACzWxWamzV+3FvEWyuz2FVQwQB3B56/djg3JZ3sqf/vO0dzw9u/cPsHm/j6vosI8Tp3sGqaxp++T2fBL7ncMS6Cp6dGd9uIcBLGQgjRi0UHuvHijDiemBLFp5sOsTrzKHeOj2j38jFLsrcxMiLUkxGn9DYvrKglvbCSIA8nBvm5tNvRLtjTiXm/GsHtY0t5/rs9PLwojYXrD/Ls1cOIC/Y4a31Ts0b20Wp2H65gd0ElqzOPsr+4mnBvJ166IY7rEoPO6qkf5OHIv+8cxYx31nPb+xv54t6L2u1Jr2kaf1u6j/fX5jB7bBjPXNV9QQwSxkII0Sd4OdtdUM91SzlxvttcoyK8+N8D4/lqaz4v/bCPW+f9yKshaxnpfJQMz4n81DyStMI69hZWtnZgc7A1EDPAnTduTmBabOA5O7EN9nflgznJ3PreRuZ8uIlP7xmD2xnTmGqaxss/ZPDu6mxuHRPKH68Z3u1jpEsYCyGEsCqjQXFTnCfXVm2ned2bOB6toqTYjbG5SxiuObHR+RLyhl2Hx5BxxAR7EOnjbFYv8hNGBrvw4bXevLt4OV/8cymzozRsyg+CjR0EJ7PosD/vbbbhllGRPH9NjFUmK5EwFqK3On4M0v+nz+Yw5EpwD7J2idpWXQyFO8HFF9xDwNFTnzZKdI6mwdEMqC2FoJFgc+Ejg/UIjXWw9UNY8yr2x4/CkCspHPEoaQ0DSDDtIiBnMZenfwsZS+FoJMTfAnEzwTPs5Dbqq6HyMFQWtNwehsp8KMuF0hyoyGeMZmKMLVABDZvs0XwiUQ3HYc9ibgFmONphU5qA+mkUhIyC4FHgFthth0HCWAhr0DQoPwjHDoBvFLgNMC+gGo7DviWw63M4sAKaWwaH+P4RCIyHoVP1JSDWeoGnaVC0GzKWQeYyKNjKaYNU2jqDe/ApS4j+Q0Jr1vevoRoaak65fxwajhNdUQfGreA3TD9mHmGcNuRWV6qrgOJ9YGoA36Hg7Nv1x9fUBEd2wMH1cGg9HPxFD2IAWycIHw8DL4VBl4L3oPbLY2qEIzvh0EZ9O/lbGN3YDIei9UDzDNePpWe4vpzvjyVNg5pjUJEHVUfAwR1cA8A1EGzbaLY2NULax7DqJT1EIybApE8gZBSBgB6DwZA4BeqrYO83sONTWPlnfRmQqAd55WGorzh7+07e+n4FJ0HsjeAVAV6RfJpl5OmfipkZEEawpyMf/biRBwaVMjukGJW/GTb9C9bP07fhHgJ3/QyuXT9xiISxEN3B1KR/IeZthEMb9KX6lPmGXfz12s6AERA0Qv+icfI6+d7sVD2A07+DxuPgFgRjH4DYm8BoBxnf6zWH1L9B6l/1L5GhU/QlbLzeHNeVGusgdy1kLoXMH/QvZND3aeLvIXQM1JZBRX7Lcki/PbITjh89e3vKCHYuYOfcsjjhXlEAP686uY6tkx6MvtHgF61/6YaOvbCQrK/Wa5/Fe+HoPihO15eqw6ev5+Ch/yDwHaLf+gzVy+IefP5BVl2kf1b+Fji4DvI36z9GADwjWv4tL9I/OzsVDvwM+3/UX3cPhUGT9HAOTtK3c2gD5G3Qt9dYo6/nEQrh46g6UohjfSWkf6sH6KnsXPUaoYOHHqhtLUZbPQQr8qA87+S/a1MtbXL01EPZNVDftrMv7P0flGZDcDJc90+IvKT942PvComz9KX8EOz8DA6k6v8PIiboP2bdglpuB7T8AGj7uudbwiC/aR9vrTwAwPWJMdx2YzzqREezpoaW/6ub9Ftn3za3Y2nq1IHUu1NSUpK2ZcsWi20vNTWVlJQUi22vP+vxx7JwJyz5Hdi76P8RIy6BgLjuqyWZo64C8jeTu+Yzwg1HIH+rHqKgf3GGjoaQ0foXePE+vfZ4eBuUZJ7chmeEXgvM36QHloM7DLsO4m6C0Iva3t/qo3ptNGOpXnNuqtVrCOMfgeS72v2CalOzCXZ/BatfgapCMBjBYKMHpcHm5GODjf5F3HhcD8iBk2DIFTD4CvNqFI21Ldu3ORnARruzQi01NZWUMYktYdkSkkdbbquL9JUC4mDcw/pxMppZ16gtg7RPYNtCPYBPsHEAnyF60PtF66FvYwdHM6EkQy/H0X2nh5mtkx547iH6rUfLrXuofuvsq5f16L6TYX80Q9+PulNqd37DIWysHr6hF7XfXFqao/87H1gB2augoerka8qgt5CEjNF/DIWO0YOKM/6P11dB2UG9pabsoN60W12kl+e0pfxkS8wJLv5ntHCE6PddA/XaamWh/kOmslCvLZ+4f7xY38dJf9D/Vrq5FedEh62aBhPPXDXsgoZW7ez3pVJqq6ZpSWc9L2EsztRlx9LUCAXbIGe1Pnj/6Pv0QO2MtE/gu9+e/IV+IrwcPSH8Yj2cI1PO3WxnaZqm/1o/UevN2whFewANDQMqIEavsYWO1r8Yz3Vut64CDqedDOeiPfoXauxNMPjyzp0nbKzVa1Cb5utf1m5BcMkTkDDr3EGlabDvO1jxZz0k/GP1JlHNpH8ZNzdBc/PJ+5oJnHz0L9XwizsX+J1wzr/LmlK9lvfLP+DYfr158qKH9H21a+fa0sPbYfN7sOsr/UdL8CgYPPlk+HqG6z84OnK8RA/Ukgwo2a//LZQf0muNtWWnr6sMenP8CY6eLTX7qJaadpT+7+10HnNQmxr12vThtJMtBfZtj2F9Xv/HNU2vYddVQFP9OWufHWo2mXdsewFLhbE0U4uu09ysnzvMWQ05q/RzXiea3QC2LIBpr+jNbx1pqoelT+gdPcIvhhkfgIuf/iv7xPazV0H6N/r6rgMgeOQp58MiWu6HnDvQGmr083K1ZfrSWAemev3zTQ3QVKc3Y514rmiPHr5Vhfr77Vz1L8GUJyFkNGtzarn4sqnmHzMHd7257lxNduaydTzZVJ2zGpY/B9/+Gn55U286Hnbd6bVrTdNDe8Wf9B8C3oNhxodnr9cTOXnByNmQeBtkLIF1r8OSx2DlX2D0/0Hy3eDsrf9A2bNYD+GCrXpNNn4mJN0JgXHn99nOPvoSPu7s1+qr9GbcEwFddVgPMd8oPTAtee7ZaKvXpMMussz2zqTUydMGF6qPBLElSRgLy6mv1sO3cKd+zit3zckmPO9Beg/IiAl6mB7br9dwP70Zoq6CKS+1X2Msz4PPb9cDYtxvYNIzJ2t2boH6l2n8TD1MSrNPBnPRHsj8UQ/OVkpvqvMI07+ca8v10K0p1UO4qa5z++weAmHj9CbAkNHgP/y0LxpTXmrnttdVIibAXcv1oPr5BfhyLgT8HS59Vu8AlLdRf/7gWr1J9dq3IO5m85t6ewqDAaKvgqhpeivFujf0c+jr3tBbFnJW6//ePkP0v7n4m/UfQF3F3hX8h+mLEOfQy/6niR6jqgiO7NJ7ex7ZpQdwaTatvWbdgvRzhhET9OXMoHX2hv9brfdaTH0R3hqlh+you0//1Zz1M3x1l94cOvNj/Yu2PUqB90B9SbpDf665We8odeJcWFluy7mxXP3cn6OHHqiB8XrtytHr5K2jp167tLEHo71+vtBo3/LYruXWtv3y9DRK6SE15ErY9YXeI/XjG/RWg7IccPaDKS/rNczeftmMUi3nXMfq52V/+Yfe9B45EZLv1H8QyuVVogeRMBbmO34MtrwPWz/Sr+E7wSNMb+KLv1nvQBMQa96lOkZbGP9bvRn0+0dh2ROwcxFc/YZ+nnLNK3ozo180zPyPHrKdZTCc7GEZNrbz7++LDEb932r4dNi6QA/mkbNh1D2WaYLsafyi4bq3gbetXRIh2iVhLDpWkgUb3oK0T/WOLoMu0y+rCYwD/xi9dnkhvCLg1q9gz9ew7CmYn6I39x7ZpXdcuvr1vhkS1mZjB6Pv0RchhFVJGPc1eZv1L1n/2AvrdKNpeoer9fP0y2SMdvp52TEP6D0/LU0piLlBv07y5+dhxyKY+op+OY40Jwoh+jgJ477C1Ag/PK1fxgL6+c6wcfo1uBET9OtZOwq15mY4Xoxf0Wr41x/1Sz+cvOGSx/VQdPE79/stwdEDrnpND+Ke3oNXCCEsRMK4L6guhs9nw6Ff9JprYBzkrNF7ju77Tl/H2Q8iLtY7rrgG6ud8K/KhokAfiq4iT79MqLmRYaD3fr7q7/o4sG0NZdfVJIiFEP2IhHFvV7AVPrtNvzRn+nsQd6P+fPzN+m1Zbst1uC3hvPurk+812LR0bgrWL8txDwa3INIKakm49kEJRCGE6CYSxr3Z9o/1a3Vd/OHOH/TLc850YvD3Ebfr54GPZekj6LgF6c3ObVx8X56aKkEshBDdSMK4Nzr1/HDEBJixQL9utyNKgc/gLi+eEEKIzpEw7m1OPT889kG47LneN0qSEEKI08i3eG/QbNIHf89arg/SUFt2+vlhIYQQvZqEcXeqyNdrtq6B7Z6vbVVVpM9XmrVcH7y/tgxQ+tyfv/rs/Ae1F0II0eNIGHeH5mbY+E9Y/kd95h/Qp1Jz8QfXAH2GIdcAPaQbqvUQPrJLX8/ZD4ZM0Qfzj5xo3rlhIYQQvYqEcVerPAyL79VnEho6VZ9ftbpIn3KvqmXC7fKDcGi9PmuQwUaf8/bSZ/VhJ/1jpGezEEL0cRLGXWnPf+Hbh/Xa8NVvwIjZ5x4Fq6lePz/c3mToQggh+iQJ465QVwnLnoS0j2HACLjhPfNmHOrt09YJIYQ4LxLGlnZoI3x9tz685ITH9XGde9Oct0IIIbqdhLElNNZC0R5I/xZ+eVOfrH7uUggdY+2SCSGE6AUkjDur4Tgc2Q2FaVC4Q7/+9+g+0Ez66/G/gikvgoObdcsphBCi15AwNlfeJvj2N3A0HbRm/TlnXwhMgKFTYEACDEjUJ1sQQgghOqH/hHHZQf1a3vPpJNVwHL66S+/pPOF3egAHxuszHsnE90IIIS5Q/whjUxO8Mx5Cx8Itizp/3e7PL+jXAs9ZAuHjuqaMQggh+q3+MZpE+UGor4T9P8CGtzr33kMbYeM7kHyXBLEQQoguYVYYK6WuVEplKKWylFJPtvF6ilKqQimV1rL8P8sX9QIczdBvfaP0ISnzt5r3vsY6+OZBfe7fy/7YRYUTQgjR33UYxkopI/AWMAUYBtyilBrWxqprNE1LaFmet3A5L0xJpn77q8/1caC/nAO15R2/b/XL+nuvfgPsXbu0iEIIIfovc2rGo4AsTdOyNU1rABYB13ZtsSysZL8+KYNnGMz4QB8v+puHQNPaf0/hTlj7d4i/BQZf1n1lFUII0e8o7VyBBCilZgBXapp2V8vj24DRmqY9eMo6KcBXQD5wGHhM07Q9bWzrHuAeAH9//5GLFi2y0G5AdXU1Li4ubb6WuO1xmg127Ej4EwAhh75mYPZHZA6+l8NBU85aXzU3MWLb77CvL2XTqHk02favWvG5jqXoHDmWliPH0nL6+7E0aSb21O7huOk4ofahBNgGYFTnmNL2HDp7LCdOnLhV07SkM583pzd1W9funJng24AwTdOqlVJTgf8Cg896k6bNB+YDJCUlaSkpKWZ8vHlSU1Npc3uaBhuKIOaGk683T4BPDjMk+0OGTJp19tzAa16F6my4aSHjh11tsTL2Fu0eS9FpciwtR46l5fTGY1nZUMnBioMcrDrIwcqDHKs9xkj/kVwcfDFuduYNslRcU8xXmV/xZeaXFNcWtz7vaONItFc0MT4xxPrEMtxnOMEuwSgzLl211LE0J4zzgZBTHgej135baZpWecr9JUqpt5VSPpqmlVxwCS/U8RKoKwefISefMxjg+nf0y52+nAv3rAL7ll82RzMh9UWIvgaG9a7WeCGE6O00TWPH0R1sKdrCwcqDrUtpXWnrOgqFk60TX2R+gY2yISkgiUmhk5gYMpEA54CztrfpyCY+y/iMFYdWYNJMjAsaxx+G/IEI9wj2HNvD7pLd7CrZxaJ9i1jYvBAAD3sPYnxi+PP4P+Pl4NXl+21OGG8GBiulIoAC4GbgV6euoJQKAIo0TdOUUqPQz0Ufs3Rhz0tJS09qnzMq6s4++mxKH10N3z8C17+r16K/eQhsHWHqK91fViGE6EGatWYq6yspqy+jor6CsroyyuvLqW6sxt5oj6ONIw42DjgYHXCwcdAfGx1wtHUkwCkAo8H8pt/9ZftZkrOEpTlLKaguAMDX0ZdQt1AmhkwkzC2MMLcwwt3CCXYNxsZgw86jO1mRt4KVh1byl41/4S8b/8Iw72FMCpnE+KDxbC/ezmcZn5FbmYu7vTu3D7udG4fcSIjbyfpluHs40yKnAdDY3EhWWRa7Snaxu2Q3GWUZZte6L1SHYaxpWpNS6kHgB8AIfKBp2h6l1L0tr78DzADuU0o1AbXAzVpHJ6O7y4me1KfWjE8IHw+XPAGpf4WIS6ChGvI2wHXvgKt/95ZTCNFjaZrG9znfs6lwE81aMxoazVqzfl/TaEa/b2+0J8YnhkS/RIZ4DsHG0H3jKmWVZbEsdxmbj2zG39mfge4DGegxkEiPSEJcQ7A1tD17XEV9BQfKD5Bdkd16W3i8kPK6cioaKmg+MfxvJznaODLEcwjRXtFEe0cT7RXNII9B2J4yi11BdQFLc5ayJGcJ+8v2Y1RGxgSO4b74+0gJScHd3v2cn5Hgl0CCXwKPjHyE7IpsVh5ayYq8FcxLm8e8tHkAxPnG8Zfxf2Fy+GTsjecegdHWYKuX1Tuam4bedF77fb7M+kvRNG0JsOSM59455f48YJ5li2YhJfvB1km/VrgtE34HuWthyWOAgkGXQfzN3VpEIUTPVXS8iOfWP8eagjV4OXhhb7THoAwoFAZl0O8rhQEDVY1VfJf9HQBONk7E+8aT6JdIon8icT5xONk6tW5X0zRqm2opry+nrL6M8jr91sXWhUEegxjgMgCDOvcFLwcrD7IsZxnLcpeRVZ6FQRkY5jWMnUd3sjRnaet6NgYbwlzDiPSIJMI9gvTSdP79w785UH6AY3UnGzEdbRwJdwtnkMcgvBy88LD3wNPBU7+198TdwR1Pe0+cbZ1pMDVQ11RHramWuqY6fTHVUdtUS3VDNVnlWew9tpdvs79lUcai1nIM9hhMlFcU2RXZ7Di6A4AE3wSeGvUUk8Mn4+Poc17/TpHukUTGRnJn7J0crTnKhsINDPIYRLR39Hltr7v1/eEwSzL1Jur2hsA0GGH6v/Tzx011cNXrMt60EBbUaGokuyKbENeQ08LIHBX1FaQVp7G9eDuHyg5Rk13DYM/BhLuHt1vTsxRN0/jmwDe8uOlFGpsbeXLUk9wSdUuHAXnk+BG2F29nW9E2thdv5587/omGhlEZGew5GE3TKK8vp7y+nHpTfbvbcbRxZJDHoNMXz0E0NTfxQ+4PLMtdxt5jewEY4TfirDCraawhpzKH7HK9xnug4gAZpRn8fOhn7LBjiMMQJgRP0EPMI5KBHgMJdA7scP86q1lrJq8qj/Rj6aSXppN+LJ1V+avwdvTm4REPMyViCkEu7VSWzpOvky9XD+xdnW/7RxiHjD73Om6BcMcP0HgcPELOva4Qwiz5Vfl8mfkli7MWU1pXikIR5hZGlFcUQ72GMtRzKFFeUfg4+qCUQtM0CqoL9CAr3sb2ou0cqDgAgI2yQdM0flrzE6A3J0a6RzLEc0jrEuASQH1TPTVNNdQ01px2W9tUS1NzE4l+iYzwG3FaU2lbimuKeW79c6zOX80IvxG8MO4FQt1CzdrvAOcApkRMYUqEftlkVUMVO4/uZFvxNvaU7GltCvW098TDQa9xnqiButu7U1FfQVZ5lr6UZbEqfxWLsxaf9Tkx3jE8lvQYV4RfcVanJQAnXnoFfwAAGe5JREFUWyeGew9nuPfw055vNDWydvVaJk6caNb+XCiDMrSe770y4spu+czeqG+HcUMNlOdB4m0dr+szqOvLIwBIK04jpyKH6wZdZ9alA6L3aGpuYlX+Kr7I+IJfDv+CUooJwRO4LPQyDh8/TEZpBrtKdrEsd1nre7wcvIhwjyCvMq/1chNXW1fi/eKZFjmNRL9EYnxiWLtmLaEJoWSWZZJZlsn+sv1sPLKRb7O/7VQZXWxdGDtgLJcEX8L4oPF4O3q3vqZpGt9lf8dfN/2VRlMjjyc/zqzoWRdUW3S1c2Vc0DjGBZk/tn2CX8Jpj0vrSjlQfoD9ZftpbG7k/7d37/FRV3fCxz9nfjOTmUlmcp8kJJAEghQMEBQq1gt4qYpV4dV2tX21xUd31xd2WXx2S5/ug6/W2i6uvWy7rbLddrvuoy+tT7tahXYVHmqhtVVBRFSUay5AyD0hl8nMZG7n+eM3mQSCkoRJhgzf98vf6/x+vxlmDkfNN+d3vuec66dff1oS0ljYDJv8f3cBSu9g3HkU0CMzqUXKvFz/Mg/+6UHCsTBvtb7FQ1c+dM5eirjwtfS38PyR5/n14V/TFmjD6/KyZuEaPj3702fttfWGejncdZhDpw5xqOsQtT21LC5ezGXey6jx1lCVUzUiE9eqrIle8HDdwW6OdB+h1d+Ky+rCZXOZ5fBzm4tILMKu5l38ofEPvNr4KtuPbUehmF8wn2vLruXyost58v0n2dm4k0XeRXz7qm9T7imf0HYbrTxHHnnFeSwpXpLqqogJkt7B+KMyqcWk0lrz5PtP8s9v/TOXF13OZd7L+Pf3/p0Wfws/XP5D3PaLZ5Uzrc1M3KiOEo6F6Qv1nXb0hnrpC/XhC/vwhXxk2jIpcBYkjnxnPvmO/BG/xPjDftoD7bT52+gIdNDmb6Pd304gEqDQVUiRq8g8Ms0yy376qkGhaIgTfSdo6G1IzO1s6GngRN8JgpGgmaQ0mLAUT15SSqFQtAfa0VrzidJP8OAlD3Jt2bUfmUnssXtYXLyYxcUjFiIasxxHzqiClN2wc92M67huxnVorTnYdTARmDft24RGk2FksH7xer4494tjmpYjxPlK82B8BFCQNyvVNbmoRWNRvrfnezxz4BlurriZjVdvJMPIoNxTzjdf+yarX17Nv97wr5RklaS6qmOmtaYz2MlJ30mafE2J42S/ed3e1456VhGNRYnqKNFYlIiOjPrz7RY7oVjorK9lZ2RT4CggRox2fzu+sG/EewbngnYPjNwYJdOWSZGriJyMHFr9rTT3N582jSXfkU+5p5yrSq8iy5Y1NJVn+LSe+HmRq4hVVasoc5eN+u+WSkqpxBSWNQvX0Bno5M3WN5mXN2/UY8NCJFOaB+PD5uYQNkeqa3LRCkaCbPjTBrYf286X5n2J9YvXJ8bfVlatpCiziL/b8Xd84aUvsOmGTaOahvB+5/tsa9hGpaeSmypuItOWOdF/jQR/2M+e1j3sat7F7pbd1PfUj8iIzcnIYVrWNKpyqiiNllI+vRxDGRgWA6uyYlgMDGVgtVixKitZ9izcdjduuxuP3ZM4d9vc2AwboWiIzkAnHYEOOgIddAaHzjsCHViUhU9M+wSFzkK8Li8FzgK8Li+FrkLcNjdKKULREG3+Nlr9rbT2tw6d+1vpDHSyoHABd8y6I7GowgzPjIvqaUW+M59bKiS5SKROmgfjI1AwJ9W1uGj1DPSw7vfr2Nu2l68u/iqrL1094j1LS5by1Iqn+PIrX+burXfz/WXf59qya0e8zxfy8VL9Szx3+DkOdB1AodBo/mn3P3Fzxc2sqlrFZd7Lkp6YEo6F2d+xnzea3uCN5jd4t/1dIjqC3WKnxlvD5z/2eUoySyjNKmVa1jSmZU077ZeDnTt3svzjy8+rDnbDTklWyXk9ObAbdsrcZVOm5yrExSZ9g3EsCp1HYOayVNfkotTka+L+393Pib4TfG/Z9z6y1zE7dzbP3PoMa19Zy7rfr2PDFRu4c86daK15r+M9njv8HFsbthKIBLgk9xI2XLGBWytvpb6nnheOvsDW+q28ePRFZrhnsKpqFbfPuv2sSUPn4g/7qe+pp7anlrruOg6dOsTe1r34I34Uinn581h96WqWlixlkXcRDqs8cRFCJEf6BuOeE+YiHpK8Nen2d+xn3e/XEYwG+eknfzqq5Bqvy8t/3vKfrP/Der79xrfZ27Y3MX3FaXWyonIFn539WaoLqhO938Gl8L625GtsP7adF46+wI/f/jGP73ucK6ddyZKiJeajYIv1rI+JB6ID5oII8eDb1D+0/4nVYqXCU8Hts27nipIr+Hjxx8+5NJ8QQoxX+gbjjiNmKcF4woWiIfa07uHVxlf508k/0dDbQHFmMU998imqckc/fzvTlslj1z/GI7se4b8O/xfz8ufxjSu/wYqKFSMyf4dz2VysrFrJyqqVnOg9wYu1L7L56Gb+fPLP5/zODCODyuxKarw1fCbnM4nViD5qLV8hhEi2NA7GMq1pIjX5mhLBd1fLLgKRAHaLnSUlS/jcxz7HisoV49p2zGqx8vWlX+fLNV8e1xq10z3T+dtFf8vamrUEIoFEBnNUn57NHI1FsVqslGSWyBQWIUTKpXcwduZBZv653ytGxR/2s7l2M7869CuOdh8FoDSrlJWzVnJN2TUsKV6C0+o87+9RSo17sfjhnzHWdZCFECJV0jgYH4FCyaROhsa+Rp49+CwvHHmBvnAf1fnVfHXxV7m67GoqPZWytJ4QQpyn9A3G7YfgY7emuhZTltaat1rf4ukDT7PjxA4UipvKb+IL877AwsKFqa6eEEKklfQMxv4u8HfIePE4BCNBdvl2sem3mzjYdZDsjGzurb6Xu+bcNa7pQkIIIc4tPYOxZFKPidaad9rfYXPtZrbVb6Mv3Mes7Fk8dOVDfGrmp5IyDiyEEOLDpWkwHsykvnh2a9Ja88rxV3jqg6dwGA6qC6qpLqhmfsF8Cl2FZ/0zLf0t/Kb2N2yp3UJDbwNOq5MbZ9xIua+c+265T8aChRBikqRvMDbskHNhbH82kbTWvHryVR5/+3EOdB2g3FOOy+riif1PENVRAIpcRcwvmM+lBZcyv2A+7YF2Nh/dzK7mXWg0lxddzr3V9ybWed65c6cEYiGEmERpGoyPQH4VpPH8Ua01rze/zqa3N/Fux7uUZZXxyNWPcGvlrRgWg0AkkNjIfX/HfvZ37Od3x3+X+POlWaWsWbiG22fdznT3+DYpF0IIkRxpGowPQfGCVNdiwuxp2cNjbz/G3ra9FGcW880rv8kdVXectmKU0+pMLBc5qDvYzfud7ydeG9w9SQghRGqlXzCODMCpBqj+bKprknSNfY186/Vv8Xrz6xQ6C9lwxQY+M/sz2A37qP58jiOHq0qvmuBaCiGEGKv0C8ZddaBjaZdJvbt5N1/5w1eIxqKsX7yeu+bcJbsGCSFEmki/YJxmmdRaa3556Jc8uvtRyj3l/Pj6H1PuSf/ENCGEuJikbzDOH/1uQReqcDTMI7sf4bnDz7GsbBmPXvPoR+5eJIQQYmpKw2B8BDxlkDG1g1ZnoJO/3/n37G3by1/N/yvW1qyV3YWEECJNpV8wbj8EhVN7vPhA5wHW7VhHd7Cb7177XVZUrkh1lYQQQkyg9JrborXZM57CyVtb67ey+uXVaK15csWTEoiFEOIikF49494mCPdPueStSCzCa02vsaV2C9satrHIu4gfLP/Bee/pK4QQYmpIr2CcyKS+8HvGWmsOdh1kS+0WXq5/mc5gJ9kZ2dxTfQ9ra9aOeu6wEEKIqS/NgvGFv1tTa38r/13/3/ym9jcc7T6KzWJjWdkybp91O9eUXoPNsJ37Q4QQQqSVNAvGhyDDA1lFqa7JCI19jXz3ze+y88RONJqFhQv5+tKvc3PFzWRnZKe6ekIIIVIozYLxYXO8+ALacSgSi/D0B0+zad8mlFL89YK/5o5Zd8jCHUIIIRLSLBgfgZnXpboWCfs79vPw6w9zsOsgy6cv58ErHqQ4szjV1RJCiClJh8PE+vvNIxTCWlCA4XaP77MiEWLBIKDM/ptSIw4FYLNNypayaROMjYgf+poviEzq/nA/j739GM8efJYCRwE/XP5Dbphxg+wRLIQQcVprYj4fkdZWIm1thFvbiLS1mdftbUQ6u4YCb/zQodCIz7FkZmItKcZWVGyWxSXYiouwFhURCwSItLebR1v70Hl7O9GuLnM67Dlc8ubucQf8sUibYOzynzRPUpy8teP4Djbu2kibv40759zJA5c9gNs+8f8ihRAXJx2LEenoINLSQri5hUh7O3pgAB0Oo0Mhsxw84tfuU120v/suRk4ORm6uWQ47lN2ODgaJDQyYnxUMEgsOoAfiZci8b94zr833hsz3DAygA0FiwSA6GCAWCBILBobuBQJETp1CBwIj/j4WjwdbkRcjLx9baSmWrEwsmZkYmWY5eCibjUh7B+GWFiItzYRbWgkePkS0vWNkI1ksWAsKsBYWYisuxrlgAdbCQiyZmfGArEFrtNagMe/F76uMjIn+VwikVTBuNE9SFIw7Ah08susRth/bTlVOFd9f9v3T9hIWQkycSFcX4eZm8wduXh7KNjmzEnQsRripiVBtLQO1dYRbmlE2G5aMDJQ9A5WRgcqwD13b7TD4gGzwh348ECSCQUyjIxF0JAzRKDocQUciEDXLWH8/4eYWwi3NRJpbCLe1QTj84ZW02bDYbGab2M3S0dNLxx9fHVXPcKyU3Y7KyMDicKCcTrN0OLA4HFgK8rE5nFgcGRg5uVi9XqxFRVi9hdiKirB6vViczvP6fh0KEY73sJXDgc3rxcjLQxkX9nLC6RWMLVbIq5z0797WsI1/fOMf8Yf9PHDZA9x96d3YLDJFSYiJoMNhgocPE9i3j8C+dwi88w7h48dPe4+Rm4u1sDDRG7IWFmDkF2BxubA448HB6TSDxrCAAcQDXxQdD4REI+Z5JEK0s5OBujpCtXVmWV+PHhhIfK/F5ULHYuhgcOIawGbD5vViLSnGuWgRnpJirMXF2EpKsBUXY/V6UQ4nFrvtQ8c7d+7cybJrriHa20u0u3vY0UP01Cl0OIzFMfjLhCN+Hi8dDpQ9Y+j1087tKEtqF3ZUdjv2sjLsZWUprcdYpVcwzq2ESZyn2x3sZuOujWxt2Ep1fjUbr97IzJyZk/b9QqQbrTWxfj+xvl6ivX3xspdoTy9ZO3Zw7Of/QWD//kSwMwoLcNXUkHvXndimTyfadcp8ZNvenigH6uuJdHR8dO9xLJTCVlqKfdZMMpcuxT5rJhmzZmGvrMSam5v4exAOEwuFzMe4A/HHuKGQ2RtNBEhl/jM8cchiQVmtiYPBc8MYuk5CwFOGgTU3N1FnkVrpFYxnTN5j4R3Hd/Dw6w/TE+ph3aJ13FN9D1ZL2jSnSHOxYJDQ8eOEGhoIn2wyH4kO+pAnl8qiQFnAYjEDiMViXitlPpp1ubBkuuK9T6dZulwolwtltZrBsa3dTNJpj5eDR3s70Z4eon19EI2e9ftdhkHs0kvJufMvcC5ciKumBuu0aaNKjNRaE+vtJRYIxMc/g4kyFgiYwTJgBngzCBoQD37KMMwAaFgxsj3YKyrO+ShVKQV2O4bdDllTewc5MTnSI3pEwzgDLZOSSd0b6uU7u7/DltotzMmdw08/+VPm5M2Z8O8VFycdiZhBYYyZ+DocJtJ1imhXJ+HWVkINDYSOHUuUkeaWCRkvHAvlcGAt8mIr9OK4dB5GTg4WtwfD48bidmN4suPn5r3XDh1i+U03je+7lMLIzsbIlgV2xIUpPYLxqWNYdGTCk7f+fPLPfOO1b9AZ6OS+BfexZsEaWb5SnDetNZH2dkL1DYTq6wnV1zFQX0+ovoHwSXOWgMXtxnC7h0qPGyPLLIlEiXR2Eu3sJNLVRbSzk2hPz4jvsXjMXp3r8sXYK8qxl1dgr6jAPr1sZMbomcF/MLs0FosnGcXMhKPBMhwm5vcT8/vR8XLoCKBDIawF+WbCTvywZGWN7ZeM+vqxNq0QU0aaBOMGs5ygYFzXXcfj+x5n+7HtzMyeyY+u+xHVBdUT8l1i6tBam483B4NOv5+Yv98MSIEAMb8f5759dNbWma8HAqe/3u8n2tND6NgxYj5f4nOVw4G9shLn/Go8t30KtCbW5yPa10ust4+or4/w8RMEfX3EenrBasWan481L4+M2bOxLr0CIy8fa34eRn4+1oJC7JUV5pQVmesuxAUpPYLx7Bv54zW/5NqShUn92Ma+Rn7yzk/4bd1vcRgO7l94P385/y/JMCZn3plIvqivn4GDBwgeOEj45EmUzWpO+bCa5WmHYRDt6yN6qpvoqVNmtmm8jHSfItrdc86kIA/QFj9XDkdiHHVwXNXIzSV74ULsM2dir6wgo7ISa3FxyjNShRCTKz2CMRAzHEnLpG7zt/Gzd3/G80eex1AGX5r7Je6dfy95jrykfL4YG6012u8n6vMR6+0l2ucj5usDwxg2LcWcu5iY15iRQbSri+CBAwQ/OGCWBz4gfGxoCoxyOs3HroMZrh/GMOKLI5gLItgrynHm1JhjnB43FuewAJvpOi3gvrFvH1fdcKM5neYCn+cohEidUQVjpdQtwI8AA/i51vrRM15X8ddvBfzA/9Ba701yXSdcd7CbJ/Y/wS8O/oJoLMqnZ3+a+xbcR1HmhbcL1IUq8eg2YI4Tnu2IhULoQMAMqokpLH1E+/pGXvf2EvX5PjTDdrRsZWU45s4lZ9UqMubOxTF3HlZvYeKxrTmnNHzGETETiLKyxt1TjdXXY2RlnlfdhRDp75zBWCllAJuATwKNwJtKqS1a6w+GvW0FMDt+XAH8JF5esGI6Rkt/C7XdtdT11HG0+yjbj23HH/Zz28zbuL/mfqa7p6e6mpNOh8Oo/n5CjY3EfD4zKPp85rnPF++Vxscve3rNx7i9PeZYZl8fsZ4e9Djmc1pcLiweD4Y7y8yeLSzAPnNmPBi6h7Jq469bssxl7BJTVQJnLrsXwOLx4Jg7D8fcj2F4PB/5/cowzJ5rfOEHIYSYTKPpGX8cOKq1rgNQSv1fYCUwPBivBJ7SWmvgDaVUjlKqRGvdnPQan0UgEqAt3MbRU0cJx8KnH1GzDEVDNPoaqeuuo7anlvqeegKRoXVR8xx5XF16NWsWrKEqt2oyqn1WQ4sFhNHhEPos5eCyeDoSPW2ZPPM6jB4IDVsHdihYxQJ+8148uei0hKL+eCZsOIwXqP2oShoGhsdjZvR6sjHcbmzTpmG4PRjZHjNYOp3xZfHsWOx283zYYXE4zOCblWX2PK1pM2IihBBjNpqfgKXAiWHXjYzs9Z7tPaXApATj97b/kqqvfYfeYfcUYI8fg7zA5SgsyoJFKZSyYMGCRVlQ+IAdRNnBoQmqp4ahKSL6jPVoh00dSTZltyfGUhPrxWZmYmRnYyspGVqgIT7eWdfUxCU1i7BkZZk90awsLFluLFmZGG63uRyeZOUKIUTSjCYYn+2n7pnZLqN5D0qp+4D74pc+pVQy414BcJbtOsQ4SFsmj7Rl8khbJo+0ZfKMtS3Lz3ZzNMG4ERg+eFoGNI3jPWitfwb8bBTfOWZKqT1a68UT8dkXG2nL5JG2TB5py+SRtkyeZLXlaFJE3wRmK6UqlVJ24HPAljPeswVYrUxLgZ7JGi8WQgghprpz9oy11hGl1FpgG+bUpie01u8rpdbEX/834CXMaU1HMac23TNxVRZCCCHSy6hSWLXWL2EG3OH3/m3YuQb+JrlVG7MJefx9kZK2TB5py+SRtkweacvkSUpbKp3inVuEEEKIi50sgCuEEEKkWFoEY6XULUqpQ0qpo0qpf0h1faYSpdQTSqk2pdT+YffylFLblVJH4mVuKus4VSilpiuldiilDiil3ldKPRC/L+05Bkoph1Jqt1LqnXg7Phy/L+04TkopQyn1tlLqt/FractxUEo1KKXeU0rtU0rtid9LSltO+WA8bLnOFcA84PNKqXmprdWU8n+AW8649w/AK1rr2cAr8WtxbhHgK1rrucBS4G/i/y1Ke47NAHC91nohUAPcEp+lIe04fg8AB4ZdS1uO33Va65ph05mS0pZTPhgzbLlOrXUIGFyuU4yC1vqPQNcZt1cCT8bPnwRWTWqlpiitdfPgBila6z7MH36lSHuOiTYNbvBsix8aacdxUUqVAZ8Cfj7strRl8iSlLdMhGH/YUpxi/IoG54nHS2+K6zPlKKUqgEXALqQ9xyz+WHUf5nbQ27XW0o7j9y/A/wKGr7UrbTk+Gvh/Sqm34itKQpLaMh1W5x/VUpxCTBalVBbwPPA/tda9so732Gmto0CNUioHeEEpVZ3qOk1FSqnbgDat9VtKqeWprk8auEpr3aSU8gLblVIHk/XB6dAzHtVSnGJMWpVSJQDxsi3F9ZkylFI2zED8jNb61/Hb0p7jpLXuBnZi5jVIO47dVcAdSqkGzCG865VSTyNtOS5a66Z42Qa8gDlMmpS2TIdgPJrlOsXYbAHujp/fDWxOYV2mDGV2gf8DOKC1/sGwl6Q9x0ApVRjvEaOUcgI3AgeRdhwzrfX/1lqXaa0rMH82/l5r/UWkLcdMKZWplHIPngM3AftJUlumxaIfSqlbMcdFBpfr3JjiKk0ZSqlngeWYO4+0Ag8BLwK/AmYAx4G/0FqfmeQlzqCUuhp4FXiPofG5DZjjxtKeo6SUWoCZCGNgdhh+pbX+llIqH2nHcYs/pl6vtb5N2nLslFIzMXvDYA7x/kJrvTFZbZkWwVgIIYSYytLhMbUQQggxpUkwFkIIIVJMgrEQQgiRYhKMhRBCiBSTYCyEEEKkmARjIYQQIsUkGAshhBApJsFYCCGESLH/D1QJsZU9oCPRAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "pd.DataFrame(history.history).plot(figsize = (8, 5))\n",
    "plt.grid(True)\n",
    "plt.gca().set_ylim(0, 2.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_y_predicted = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE为： 0.22380966\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error\n",
    "print('RMSE为：',np.sqrt(mean_squared_error(y_test,df_test_y_predicted)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAPE为： 0.050090764\n"
     ]
    }
   ],
   "source": [
    "import scipy\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "# from sklearn.metrics import mean_absolute_percentage_errorS\n",
    "print('MAPE为：',mean_squared_error(y_test,df_test_y_predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE为： 0.10846363\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "print('MAE为：',mean_absolute_error(y_test,df_test_y_predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Height</th>\n",
       "      <th>Weight</th>\n",
       "      <th>family_history_with_overweight</th>\n",
       "      <th>FAVC</th>\n",
       "      <th>FCVC</th>\n",
       "      <th>NCP</th>\n",
       "      <th>CAEC</th>\n",
       "      <th>SMOKE</th>\n",
       "      <th>CH2O</th>\n",
       "      <th>SCC</th>\n",
       "      <th>FAF</th>\n",
       "      <th>TUE</th>\n",
       "      <th>CALC</th>\n",
       "      <th>MTRANS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>1.620000</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>1.520000</td>\n",
       "      <td>56.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>1.800000</td>\n",
       "      <td>77.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>1.800000</td>\n",
       "      <td>87.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>1.780000</td>\n",
       "      <td>89.800000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2106</th>\n",
       "      <td>0</td>\n",
       "      <td>20.976842</td>\n",
       "      <td>1.710730</td>\n",
       "      <td>131.408528</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1.728139</td>\n",
       "      <td>0</td>\n",
       "      <td>1.676269</td>\n",
       "      <td>0.906247</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2107</th>\n",
       "      <td>0</td>\n",
       "      <td>21.982942</td>\n",
       "      <td>1.748584</td>\n",
       "      <td>133.742943</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2.005130</td>\n",
       "      <td>0</td>\n",
       "      <td>1.341390</td>\n",
       "      <td>0.599270</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2108</th>\n",
       "      <td>0</td>\n",
       "      <td>22.524036</td>\n",
       "      <td>1.752206</td>\n",
       "      <td>133.689352</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2.054193</td>\n",
       "      <td>0</td>\n",
       "      <td>1.414209</td>\n",
       "      <td>0.646288</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2109</th>\n",
       "      <td>0</td>\n",
       "      <td>24.361936</td>\n",
       "      <td>1.739450</td>\n",
       "      <td>133.346641</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2.852339</td>\n",
       "      <td>0</td>\n",
       "      <td>1.139107</td>\n",
       "      <td>0.586035</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2110</th>\n",
       "      <td>0</td>\n",
       "      <td>23.664709</td>\n",
       "      <td>1.738836</td>\n",
       "      <td>133.472641</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2.863513</td>\n",
       "      <td>0</td>\n",
       "      <td>1.026452</td>\n",
       "      <td>0.714137</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2111 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Gender        Age    Height      Weight  family_history_with_overweight  \\\n",
       "0         0  21.000000  1.620000   64.000000                               1   \n",
       "1         0  21.000000  1.520000   56.000000                               1   \n",
       "2         1  23.000000  1.800000   77.000000                               1   \n",
       "3         1  27.000000  1.800000   87.000000                               0   \n",
       "4         1  22.000000  1.780000   89.800000                               0   \n",
       "...     ...        ...       ...         ...                             ...   \n",
       "2106      0  20.976842  1.710730  131.408528                               1   \n",
       "2107      0  21.982942  1.748584  133.742943                               1   \n",
       "2108      0  22.524036  1.752206  133.689352                               1   \n",
       "2109      0  24.361936  1.739450  133.346641                               1   \n",
       "2110      0  23.664709  1.738836  133.472641                               1   \n",
       "\n",
       "      FAVC  FCVC  NCP  CAEC  SMOKE      CH2O  SCC       FAF       TUE  CALC  \\\n",
       "0        0   2.0  3.0     2      0  2.000000    0  0.000000  1.000000     1   \n",
       "1        0   3.0  3.0     2      1  3.000000    1  3.000000  0.000000     2   \n",
       "2        0   2.0  3.0     2      0  2.000000    0  2.000000  1.000000     3   \n",
       "3        0   3.0  3.0     2      0  2.000000    0  2.000000  0.000000     3   \n",
       "4        0   2.0  1.0     2      0  2.000000    0  0.000000  0.000000     2   \n",
       "...    ...   ...  ...   ...    ...       ...  ...       ...       ...   ...   \n",
       "2106     1   3.0  3.0     2      0  1.728139    0  1.676269  0.906247     2   \n",
       "2107     1   3.0  3.0     2      0  2.005130    0  1.341390  0.599270     2   \n",
       "2108     1   3.0  3.0     2      0  2.054193    0  1.414209  0.646288     2   \n",
       "2109     1   3.0  3.0     2      0  2.852339    0  1.139107  0.586035     2   \n",
       "2110     1   3.0  3.0     2      0  2.863513    0  1.026452  0.714137     2   \n",
       "\n",
       "     MTRANS  \n",
       "0         0  \n",
       "1         0  \n",
       "2         0  \n",
       "3         1  \n",
       "4         0  \n",
       "...     ...  \n",
       "2106      0  \n",
       "2107      0  \n",
       "2108      0  \n",
       "2109      0  \n",
       "2110      0  \n",
       "\n",
       "[2111 rows x 16 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_data.drop(['NObeyesdad'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_x=df_data.drop(['Height'],axis=1)\n",
    "\n",
    "df_y=df_data.loc[:,'Height']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = pd.get_dummies(df_x)\n",
    "y = df_y\n",
    "\n",
    "x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         [(None, 27)]              0         \n",
      "_________________________________________________________________\n",
      "nl1 (Dense)                  (None, 32)                896       \n",
      "_________________________________________________________________\n",
      "nl2 (Dense)                  (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "nl3 (Dense)                  (None, 10)                170       \n",
      "_________________________________________________________________\n",
      "nl4 (Dense)                  (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 1,715\n",
      "Trainable params: 1,715\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "input_layer = Input(shape=(x_train.shape[1],))\n",
    "dense_layer_1 =Dense(32,kernel_initializer=tf.keras.initializers.GlorotNormal() ,activation='relu', name =\"nl1\" )(input_layer)\n",
    "dense_layer_2 = Dense(16,kernel_initializer=tf.keras.initializers.GlorotNormal(),activation='relu', name =\"nl2\" )(dense_layer_1)\n",
    "dense_layer_2 = Dense(10,activation='relu', name =\"nl3\" )(dense_layer_2)\n",
    "dense_layer_2 = Dense(10,activation='relu', name =\"nl4\" )(dense_layer_2)\n",
    "dense_layer_2 = Dropout(0.5)(dense_layer_2)\n",
    "output = Dense(1)(dense_layer_2)\n",
    "model = Model(inputs=input_layer, outputs=output)\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "338/338 [==============================] - 1s 500us/step - loss: 0.9870 - mean_absolute_error: 0.9870 - mean_absolute_percentage_error: 58.0820\n",
      "Epoch 2/50\n",
      "338/338 [==============================] - 0s 488us/step - loss: 0.3220 - mean_absolute_error: 0.3220 - mean_absolute_percentage_error: 18.8519\n",
      "Epoch 3/50\n",
      "338/338 [==============================] - 0s 494us/step - loss: 0.1337 - mean_absolute_error: 0.1337 - mean_absolute_percentage_error: 7.7912\n",
      "Epoch 4/50\n",
      "338/338 [==============================] - 0s 506us/step - loss: 0.0743 - mean_absolute_error: 0.0743 - mean_absolute_percentage_error: 4.3483\n",
      "Epoch 5/50\n",
      "338/338 [==============================] - 0s 491us/step - loss: 0.0687 - mean_absolute_error: 0.0687 - mean_absolute_percentage_error: 4.0491\n",
      "Epoch 6/50\n",
      "338/338 [==============================] - 0s 500us/step - loss: 0.0644 - mean_absolute_error: 0.0644 - mean_absolute_percentage_error: 3.7851\n",
      "Epoch 7/50\n",
      "338/338 [==============================] - 0s 500us/step - loss: 0.0615 - mean_absolute_error: 0.0615 - mean_absolute_percentage_error: 3.6298\n",
      "Epoch 8/50\n",
      "338/338 [==============================] - 0s 497us/step - loss: 0.0628 - mean_absolute_error: 0.0628 - mean_absolute_percentage_error: 3.7033\n",
      "Epoch 9/50\n",
      "338/338 [==============================] - 0s 494us/step - loss: 0.0586 - mean_absolute_error: 0.0586 - mean_absolute_percentage_error: 3.4715\n",
      "Epoch 10/50\n",
      "338/338 [==============================] - 0s 493us/step - loss: 0.0636 - mean_absolute_error: 0.0636 - mean_absolute_percentage_error: 3.7526\n",
      "Epoch 11/50\n",
      "338/338 [==============================] - 0s 503us/step - loss: 0.0591 - mean_absolute_error: 0.0591 - mean_absolute_percentage_error: 3.5033\n",
      "Epoch 12/50\n",
      "338/338 [==============================] - 0s 503us/step - loss: 0.0574 - mean_absolute_error: 0.0574 - mean_absolute_percentage_error: 3.4011\n",
      "Epoch 13/50\n",
      "338/338 [==============================] - 0s 506us/step - loss: 0.0615 - mean_absolute_error: 0.0615 - mean_absolute_percentage_error: 3.6148\n",
      "Epoch 14/50\n",
      "338/338 [==============================] - 0s 494us/step - loss: 0.0620 - mean_absolute_error: 0.0620 - mean_absolute_percentage_error: 3.6637\n",
      "Epoch 15/50\n",
      "338/338 [==============================] - 0s 497us/step - loss: 0.0587 - mean_absolute_error: 0.0587 - mean_absolute_percentage_error: 3.4635\n",
      "Epoch 16/50\n",
      "338/338 [==============================] - 0s 497us/step - loss: 0.0578 - mean_absolute_error: 0.0578 - mean_absolute_percentage_error: 3.4009\n",
      "Epoch 17/50\n",
      "338/338 [==============================] - 0s 497us/step - loss: 0.0570 - mean_absolute_error: 0.0570 - mean_absolute_percentage_error: 3.3528\n",
      "Epoch 18/50\n",
      "338/338 [==============================] - 0s 496us/step - loss: 0.0573 - mean_absolute_error: 0.0573 - mean_absolute_percentage_error: 3.3752\n",
      "Epoch 19/50\n",
      "338/338 [==============================] - 0s 520us/step - loss: 0.0572 - mean_absolute_error: 0.0572 - mean_absolute_percentage_error: 3.3705\n",
      "Epoch 20/50\n",
      "338/338 [==============================] - 0s 509us/step - loss: 0.0545 - mean_absolute_error: 0.0545 - mean_absolute_percentage_error: 3.2224\n",
      "Epoch 21/50\n",
      "338/338 [==============================] - 0s 509us/step - loss: 0.0575 - mean_absolute_error: 0.0575 - mean_absolute_percentage_error: 3.3937\n",
      "Epoch 22/50\n",
      "338/338 [==============================] - 0s 497us/step - loss: 0.0530 - mean_absolute_error: 0.0530 - mean_absolute_percentage_error: 3.1273\n",
      "Epoch 23/50\n",
      "338/338 [==============================] - 0s 497us/step - loss: 0.0549 - mean_absolute_error: 0.0549 - mean_absolute_percentage_error: 3.2270\n",
      "Epoch 24/50\n",
      "338/338 [==============================] - 0s 497us/step - loss: 0.0555 - mean_absolute_error: 0.0555 - mean_absolute_percentage_error: 3.2783\n",
      "Epoch 25/50\n",
      "338/338 [==============================] - 0s 491us/step - loss: 0.0538 - mean_absolute_error: 0.0538 - mean_absolute_percentage_error: 3.1703\n",
      "Epoch 26/50\n",
      "338/338 [==============================] - 0s 500us/step - loss: 0.0518 - mean_absolute_error: 0.0518 - mean_absolute_percentage_error: 3.0562\n",
      "Epoch 27/50\n",
      "338/338 [==============================] - 0s 491us/step - loss: 0.0530 - mean_absolute_error: 0.0530 - mean_absolute_percentage_error: 3.1254\n",
      "Epoch 28/50\n",
      "338/338 [==============================] - 0s 494us/step - loss: 0.0531 - mean_absolute_error: 0.0531 - mean_absolute_percentage_error: 3.1348\n",
      "Epoch 29/50\n",
      "338/338 [==============================] - 0s 500us/step - loss: 0.0534 - mean_absolute_error: 0.0534 - mean_absolute_percentage_error: 3.1419\n",
      "Epoch 30/50\n",
      "338/338 [==============================] - 0s 530us/step - loss: 0.0534 - mean_absolute_error: 0.0534 - mean_absolute_percentage_error: 3.1354\n",
      "Epoch 31/50\n",
      "338/338 [==============================] - 0s 503us/step - loss: 0.0543 - mean_absolute_error: 0.0543 - mean_absolute_percentage_error: 3.2062\n",
      "Epoch 32/50\n",
      "338/338 [==============================] - 0s 500us/step - loss: 0.0540 - mean_absolute_error: 0.0540 - mean_absolute_percentage_error: 3.1955\n",
      "Epoch 33/50\n",
      "338/338 [==============================] - 0s 502us/step - loss: 0.0548 - mean_absolute_error: 0.0548 - mean_absolute_percentage_error: 3.2286\n"
     ]
    }
   ],
   "source": [
    "callback = tf.keras.callbacks.EarlyStopping(monitor='loss',mode='min', patience=5)\n",
    "Adam = tf.optimizers.Adam(lr=0.003, beta_1=0.9, beta_2=0.997, epsilon=1e-08, decay=0.0)\n",
    "model.compile(optimizer=Adam, \n",
    "              loss=[tf.keras.losses.mae,tf.keras.losses.mape],\n",
    "              metrics=[tf.keras.metrics.mae,tf.keras.metrics.mape]\n",
    "              \n",
    "              )\n",
    "history = model.fit(x=x_train, y=y_train,  epochs=50,batch_size =5, callbacks=[callback] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "callback = tf.keras.callbacks.EarlyStopping(monitor='acc',mode='max', patience=5)\n",
    "Adam = tf.optimizers.Adam(lr=0.003, beta_1=0.9, beta_2=0.997, epsilon=1e-08, decay=0.0)\n",
    "model.compile(optimizer=Adam, \n",
    "              loss=[\"mean_squared_error\"],metrics=['mean_squared_error','mean_absolute_error'])\n",
    "history = model.fit(x=x_train, y=y_train,  epochs=50,batch_size =5, callbacks=[callback] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.7376603],\n",
       "       [1.7587336],\n",
       "       [1.7362286],\n",
       "       [1.675612 ],\n",
       "       [1.7446326],\n",
       "       [1.7266747],\n",
       "       [1.6686889],\n",
       "       [1.7153231],\n",
       "       [1.6338176],\n",
       "       [1.6571162],\n",
       "       [1.7035944],\n",
       "       [1.7389561],\n",
       "       [1.6884967],\n",
       "       [1.7034175],\n",
       "       [1.651805 ],\n",
       "       [1.6638464],\n",
       "       [1.7056302],\n",
       "       [1.7056302],\n",
       "       [1.6566106],\n",
       "       [1.7401729],\n",
       "       [1.6576087],\n",
       "       [1.7631546],\n",
       "       [1.6568007],\n",
       "       [1.6477927],\n",
       "       [1.7386667],\n",
       "       [1.7617065],\n",
       "       [1.6901016],\n",
       "       [1.7056302],\n",
       "       [1.7677594],\n",
       "       [1.7358845],\n",
       "       [1.7255319],\n",
       "       [1.65836  ],\n",
       "       [1.6669555],\n",
       "       [1.6761172],\n",
       "       [1.7290841],\n",
       "       [1.720622 ],\n",
       "       [1.6833291],\n",
       "       [1.7357756],\n",
       "       [1.7354738],\n",
       "       [1.732702 ],\n",
       "       [1.6438048],\n",
       "       [1.6629468],\n",
       "       [1.719769 ],\n",
       "       [1.7056302],\n",
       "       [1.68092  ],\n",
       "       [1.7365031],\n",
       "       [1.7653786],\n",
       "       [1.6629926],\n",
       "       [1.7317355],\n",
       "       [1.6741805],\n",
       "       [1.7056302],\n",
       "       [1.689311 ],\n",
       "       [1.7507538],\n",
       "       [1.698523 ],\n",
       "       [1.7576507],\n",
       "       [1.7241472],\n",
       "       [1.7430037],\n",
       "       [1.7335175],\n",
       "       [1.7152117],\n",
       "       [1.6589607],\n",
       "       [1.6733088],\n",
       "       [1.7257597],\n",
       "       [1.73734  ],\n",
       "       [1.7435176],\n",
       "       [1.7041528],\n",
       "       [1.7193893],\n",
       "       [1.7171029],\n",
       "       [1.7600312],\n",
       "       [1.7284395],\n",
       "       [1.7148663],\n",
       "       [1.6888485],\n",
       "       [1.6297166],\n",
       "       [1.7276257],\n",
       "       [1.7192699],\n",
       "       [1.7440209],\n",
       "       [1.7322806],\n",
       "       [1.6501279],\n",
       "       [1.7455087],\n",
       "       [1.6664298],\n",
       "       [1.7480198],\n",
       "       [1.6495392],\n",
       "       [1.7697644],\n",
       "       [1.7381002],\n",
       "       [1.6559533],\n",
       "       [1.6595389],\n",
       "       [1.7187009],\n",
       "       [1.7406491],\n",
       "       [1.7056302],\n",
       "       [1.7305437],\n",
       "       [1.7390802],\n",
       "       [1.7617489],\n",
       "       [1.7230473],\n",
       "       [1.633515 ],\n",
       "       [1.6737939],\n",
       "       [1.7056302],\n",
       "       [1.719308 ],\n",
       "       [1.7518995],\n",
       "       [1.7059828],\n",
       "       [1.7053466],\n",
       "       [1.6296632],\n",
       "       [1.7375422],\n",
       "       [1.7187128],\n",
       "       [1.709813 ],\n",
       "       [1.7529248],\n",
       "       [1.7300645],\n",
       "       [1.7555288],\n",
       "       [1.7056302],\n",
       "       [1.7147031],\n",
       "       [1.7446337],\n",
       "       [1.7413893],\n",
       "       [1.7130764],\n",
       "       [1.6435591],\n",
       "       [1.7326647],\n",
       "       [1.71684  ],\n",
       "       [1.6564411],\n",
       "       [1.7020563],\n",
       "       [1.7112752],\n",
       "       [1.6296632],\n",
       "       [1.691838 ],\n",
       "       [1.6551123],\n",
       "       [1.6849638],\n",
       "       [1.6611164],\n",
       "       [1.7056302],\n",
       "       [1.678799 ],\n",
       "       [1.734542 ],\n",
       "       [1.660182 ],\n",
       "       [1.703839 ],\n",
       "       [1.7315263],\n",
       "       [1.6643661],\n",
       "       [1.7237495],\n",
       "       [1.6327711],\n",
       "       [1.6870873],\n",
       "       [1.7590181],\n",
       "       [1.7132293],\n",
       "       [1.6302774],\n",
       "       [1.7056302],\n",
       "       [1.7300202],\n",
       "       [1.6672325],\n",
       "       [1.6763045],\n",
       "       [1.6496812],\n",
       "       [1.6359357],\n",
       "       [1.7060633],\n",
       "       [1.6735408],\n",
       "       [1.7441521],\n",
       "       [1.7036883],\n",
       "       [1.6520848],\n",
       "       [1.7317262],\n",
       "       [1.7241626],\n",
       "       [1.7272694],\n",
       "       [1.6900741],\n",
       "       [1.6734262],\n",
       "       [1.6885889],\n",
       "       [1.6296632],\n",
       "       [1.7031585],\n",
       "       [1.7672209],\n",
       "       [1.7056302],\n",
       "       [1.7132785],\n",
       "       [1.7243567],\n",
       "       [1.7056302],\n",
       "       [1.7493438],\n",
       "       [1.7315409],\n",
       "       [1.6978141],\n",
       "       [1.7425487],\n",
       "       [1.6781942],\n",
       "       [1.7056302],\n",
       "       [1.7610203],\n",
       "       [1.6296632],\n",
       "       [1.7653683],\n",
       "       [1.6776999],\n",
       "       [1.7265565],\n",
       "       [1.7320908],\n",
       "       [1.6798881],\n",
       "       [1.7157402],\n",
       "       [1.7056302],\n",
       "       [1.7637541],\n",
       "       [1.7509372],\n",
       "       [1.7338285],\n",
       "       [1.672028 ],\n",
       "       [1.6730846],\n",
       "       [1.7625678],\n",
       "       [1.6669244],\n",
       "       [1.7056302],\n",
       "       [1.6301817],\n",
       "       [1.6406374],\n",
       "       [1.729357 ],\n",
       "       [1.7001098],\n",
       "       [1.7199944],\n",
       "       [1.7311018],\n",
       "       [1.6897807],\n",
       "       [1.6312792],\n",
       "       [1.7315409],\n",
       "       [1.7466471],\n",
       "       [1.7302084],\n",
       "       [1.6296632],\n",
       "       [1.646687 ],\n",
       "       [1.724015 ],\n",
       "       [1.7487928],\n",
       "       [1.7056302],\n",
       "       [1.7056302],\n",
       "       [1.699717 ],\n",
       "       [1.6497433],\n",
       "       [1.7412912],\n",
       "       [1.7462171],\n",
       "       [1.6666071],\n",
       "       [1.7277516],\n",
       "       [1.7056302],\n",
       "       [1.6659777],\n",
       "       [1.7607507],\n",
       "       [1.7210535],\n",
       "       [1.7152131],\n",
       "       [1.6572174],\n",
       "       [1.755693 ],\n",
       "       [1.6763979],\n",
       "       [1.7345699],\n",
       "       [1.66649  ],\n",
       "       [1.739871 ],\n",
       "       [1.724269 ],\n",
       "       [1.764649 ],\n",
       "       [1.6944995],\n",
       "       [1.6538076],\n",
       "       [1.7350658],\n",
       "       [1.6296632],\n",
       "       [1.691239 ],\n",
       "       [1.7578859],\n",
       "       [1.6675485],\n",
       "       [1.6914307],\n",
       "       [1.6606706],\n",
       "       [1.7186178],\n",
       "       [1.717133 ],\n",
       "       [1.6705731],\n",
       "       [1.6907176],\n",
       "       [1.7060921],\n",
       "       [1.7403747],\n",
       "       [1.717617 ],\n",
       "       [1.7463264],\n",
       "       [1.6935469],\n",
       "       [1.7339873],\n",
       "       [1.7275481],\n",
       "       [1.7427119],\n",
       "       [1.7251554],\n",
       "       [1.7715635],\n",
       "       [1.7056302],\n",
       "       [1.7646564],\n",
       "       [1.6905077],\n",
       "       [1.7322782],\n",
       "       [1.6899605],\n",
       "       [1.7492368],\n",
       "       [1.7240698],\n",
       "       [1.6846637],\n",
       "       [1.7236313],\n",
       "       [1.678545 ],\n",
       "       [1.7508523],\n",
       "       [1.6807042],\n",
       "       [1.7494204],\n",
       "       [1.6906335],\n",
       "       [1.7470385],\n",
       "       [1.7063729],\n",
       "       [1.765107 ],\n",
       "       [1.7056302],\n",
       "       [1.7074735],\n",
       "       [1.6296966],\n",
       "       [1.7454294],\n",
       "       [1.6600671],\n",
       "       [1.7394617],\n",
       "       [1.6536989],\n",
       "       [1.7394749],\n",
       "       [1.7484914],\n",
       "       [1.6366019],\n",
       "       [1.7399844],\n",
       "       [1.7485157],\n",
       "       [1.7217686],\n",
       "       [1.6700084],\n",
       "       [1.6351038],\n",
       "       [1.7023041],\n",
       "       [1.7078509],\n",
       "       [1.6884836],\n",
       "       [1.7517248],\n",
       "       [1.6453458],\n",
       "       [1.6929132],\n",
       "       [1.675374 ],\n",
       "       [1.6508107],\n",
       "       [1.7056302],\n",
       "       [1.7559065],\n",
       "       [1.6901263],\n",
       "       [1.7288922],\n",
       "       [1.7056302],\n",
       "       [1.7415582],\n",
       "       [1.6653515],\n",
       "       [1.7550184],\n",
       "       [1.7515624],\n",
       "       [1.6882151],\n",
       "       [1.722038 ],\n",
       "       [1.6778586],\n",
       "       [1.6678174],\n",
       "       [1.6369516],\n",
       "       [1.7056302],\n",
       "       [1.6594015],\n",
       "       [1.6665429],\n",
       "       [1.660559 ],\n",
       "       [1.6509097],\n",
       "       [1.6643459],\n",
       "       [1.7181334],\n",
       "       [1.6551056],\n",
       "       [1.7399212],\n",
       "       [1.6736345],\n",
       "       [1.7207459],\n",
       "       [1.7056302],\n",
       "       [1.751323 ],\n",
       "       [1.6767262],\n",
       "       [1.7353797],\n",
       "       [1.7179744],\n",
       "       [1.6940467],\n",
       "       [1.6643577],\n",
       "       [1.6571846],\n",
       "       [1.7377975],\n",
       "       [1.6784248],\n",
       "       [1.690912 ],\n",
       "       [1.757808 ],\n",
       "       [1.6496816],\n",
       "       [1.7258648],\n",
       "       [1.6839858],\n",
       "       [1.6481373],\n",
       "       [1.7454001],\n",
       "       [1.7017206],\n",
       "       [1.7403097],\n",
       "       [1.7824905],\n",
       "       [1.7604753],\n",
       "       [1.7056302],\n",
       "       [1.7510117],\n",
       "       [1.7056302],\n",
       "       [1.7248577],\n",
       "       [1.7218384],\n",
       "       [1.7299588],\n",
       "       [1.7056302],\n",
       "       [1.7368034],\n",
       "       [1.7194405],\n",
       "       [1.7056302],\n",
       "       [1.6612408],\n",
       "       [1.693173 ],\n",
       "       [1.7056302],\n",
       "       [1.6660092],\n",
       "       [1.7056302],\n",
       "       [1.7056302],\n",
       "       [1.7056302],\n",
       "       [1.6311258],\n",
       "       [1.6570475],\n",
       "       [1.7656649],\n",
       "       [1.7353988],\n",
       "       [1.7646499],\n",
       "       [1.7056302],\n",
       "       [1.6766931],\n",
       "       [1.7056302],\n",
       "       [1.73258  ],\n",
       "       [1.7010657],\n",
       "       [1.6724235],\n",
       "       [1.7388734],\n",
       "       [1.6506003],\n",
       "       [1.6344038],\n",
       "       [1.7531626],\n",
       "       [1.7488459],\n",
       "       [1.7467066],\n",
       "       [1.7412579],\n",
       "       [1.7273396],\n",
       "       [1.7229059],\n",
       "       [1.683221 ],\n",
       "       [1.7130361],\n",
       "       [1.7446147],\n",
       "       [1.6297596],\n",
       "       [1.7206483],\n",
       "       [1.7207586],\n",
       "       [1.7070041],\n",
       "       [1.7326719],\n",
       "       [1.6913649],\n",
       "       [1.7358053],\n",
       "       [1.6706055],\n",
       "       [1.7266132],\n",
       "       [1.6898112],\n",
       "       [1.7595943],\n",
       "       [1.7056302],\n",
       "       [1.6894612],\n",
       "       [1.6863583],\n",
       "       [1.7386662],\n",
       "       [1.656551 ],\n",
       "       [1.7634033],\n",
       "       [1.705772 ],\n",
       "       [1.761347 ],\n",
       "       [1.741645 ],\n",
       "       [1.7351546],\n",
       "       [1.7111405],\n",
       "       [1.7500495],\n",
       "       [1.6833906],\n",
       "       [1.6339555],\n",
       "       [1.6651566],\n",
       "       [1.6884611],\n",
       "       [1.6318829],\n",
       "       [1.6906961],\n",
       "       [1.7056302],\n",
       "       [1.734149 ],\n",
       "       [1.6596593],\n",
       "       [1.726248 ],\n",
       "       [1.6296632],\n",
       "       [1.7064612],\n",
       "       [1.6646479],\n",
       "       [1.7240722],\n",
       "       [1.7222122],\n",
       "       [1.7626398],\n",
       "       [1.7349176],\n",
       "       [1.7553786],\n",
       "       [1.6296632],\n",
       "       [1.7056302],\n",
       "       [1.7006955],\n",
       "       [1.742466 ],\n",
       "       [1.6739243],\n",
       "       [1.7266666],\n",
       "       [1.7176559],\n",
       "       [1.7558092],\n",
       "       [1.7584739],\n",
       "       [1.7696774],\n",
       "       [1.7284566],\n",
       "       [1.7384013],\n",
       "       [1.6449986],\n",
       "       [1.6619403],\n",
       "       [1.7668825]], dtype=float32)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test_y_predicted = model.predict(x_test)\n",
    "df_test_y_predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE为： 0.06562598082319877\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error\n",
    "print('RMSE为：',np.sqrt(mean_squared_error(y_test,df_test_y_predicted)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAPE为： 0.004306769359006854\n"
     ]
    }
   ],
   "source": [
    "import scipy\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "# from sklearn.metrics import mean_absolute_percentage_error\n",
    "print('MAPE为：',mean_squared_error(y_test,df_test_y_predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE为： 0.052006287993212406\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "print('MAE为：',mean_absolute_error(y_test,df_test_y_predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
